{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "T7ya4ArX8p1h"
   },
   "source": [
    "# Create BigQuery stored procedures\n",
    "\n",
    "This notebook is the second of two notebooks that guide you through completing the prerequisites for running the [Real-time Item-to-item Recommendation with BigQuery ML Matrix Factorization and ScaNN](https://github.com/GoogleCloudPlatform/analytics-componentized-patterns/tree/master/retail/recommendation-system/bqml-scann) solution.\n",
    "\n",
    "Use this notebook to create the following stored procedures that are needed by the solution:\n",
    "\n",
    "+ `sp_ComputePMI` - Computes [pointwise mutual information (PMI)](https://en.wikipedia.org/wiki/Pointwise_mutual_information) from item co-occurence data. This data is used by a matrix factorization model to learn item embeddings.\n",
    "+ `sp_TrainItemMatchingModel` - Creates the `item_embedding_model` [matrix factorization](https://en.wikipedia.org/wiki/Matrix_factorization_(recommender_systems)) model. This model learns item embeddings based on the PMI data computed by `sp_ComputePMI`. \n",
    "+ `sp_ExractEmbeddings` - Extracts the item embedding values from the `item_embedding_model` model, aggregates these values to produce a single embedding vector for each item, and stores these vectors in the `item_embeddings` table. The vector data is later exported to Cloud Storage to be used for item embedding lookup.\n",
    "\n",
    "Before starting this notebook, you must run the [00_prep_bq_and_datastore](00_prep_bq_and_datastore.ipynb) notebook to complete the first part of the prerequisites.\n",
    "\n",
    "After completing this notebook, you can run the solution either step-by-step or with a TFX pipeline:\n",
    "\n",
    "+ To start running the solution step-by-step, run the [01_train_bqml_mf_pmi](01_train_bqml_mf_pmi.ipynb) notebook to create item embeddings.\n",
    "+ To run the solution by using a TFX pipeline, run the [tfx01_interactive](tfx01_interactive.ipynb) notebook to create the pipeline."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8XDNl5508p1q"
   },
   "source": [
    "## Setup\r\n",
    "\r\n",
    "Install the required Python packages, configure the environment variables, and authenticate your GCP account."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dn791d8i8p1s"
   },
   "source": [
    "### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "XdHb5Au58p1t"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from google.cloud import bigquery"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9UFVH4xM8p1u"
   },
   "source": [
    "### Configure GCP environment settings\r\n",
    "\r\n",
    "Update the following variables to reflect the values for your GCP environment:\r\n",
    "\r\n",
    "+ `PROJECT_ID`: The ID of the Google Cloud project you are using to implement this solution.\r\n",
    "+ `BUCKET`: The name of the Cloud Storage bucket you created to use with this solution. The `BUCKET` value should be just the bucket name, so `myBucket` rather than `gs://myBucket`.\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "gZDEzHun8p1v"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated property [core/project].\n"
     ]
    }
   ],
   "source": [
    "PROJECT_ID = 'vertex-stuff' # Change to your project.\n",
    "BUCKET = 'jsw-matching-engine' # Change to the bucket you created.\n",
    "SQL_SCRIPTS_DIR = 'sql_scripts'\n",
    "BQ_DATASET_NAME = 'css_retail'\n",
    "BQ_REGION = 'US' # Change to your BigQuery region.\n",
    "RESERVATION = 'default'\n",
    "SLOTS=10\n",
    "\n",
    "!gcloud config set project $PROJECT_ID"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kiCcnPua8p1v"
   },
   "source": [
    "### Authenticate your GCP account\n",
    "This is required if you run the notebook in Colab. If you use an AI Platform notebook, you should already be authenticated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "iSg7I1e38p1w"
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    from google.colab import auth\n",
    "    auth.authenticate_user()\n",
    "    print(\"Colab user is authenticated.\")\n",
    "except: pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gvIYbnii8p1x"
   },
   "source": [
    "## Create the stored procedure dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "params = {\"dataset\" : BQ_DATASET_NAME}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "NxvKwbdf8p1y"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Query complete after 0.00s: 100%|██████████| 1/1 [00:00<00:00, 1173.23query/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: []"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%bigquery --project $PROJECT_ID --params $params\n",
    "declare dataset STRING;\n",
    "set dataset = @dataset;\n",
    "EXECUTE IMMEDIATE CONCAT(\n",
    "\"CREATE TABLE IF NOT EXISTS \", dataset, '''.item_cooc\n",
    "AS SELECT 0 AS item1_Id, 0 AS item2_Id, 0 AS cooc, 0 AS pmi;''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Capacity commitment vertex-stuff:US. \n",
      "\n",
      "                  name                   slotCount   plan   renewalPlan   state        commitmentStartTime            commitmentEndTime       \n",
      " -------------------------------------- ----------- ------ ------------- -------- ----------------------------- ----------------------------- \n",
      "  vertex-stuff:US.13026502379002309196   100         FLEX                 ACTIVE   2021-09-30T20:59:09.375232Z   2021-09-30T21:00:09.375232Z  \n",
      "\n",
      "BigQuery error in mk operation: Failed to create reservation 'default': Error\n",
      "reported by server with missing error fields. Server returned: {'error':\n",
      "{'code': 409, 'message': 'An active reservation default already exists',\n",
      "'status': 'ALREADY_EXISTS'}}\n",
      "BigQuery error in mk operation: Failed to create reservation assignment '':\n",
      "Error reported by server with missing error fields. Server returned: {'error':\n",
      "{'code': 409, 'message': \"An assignment already exists for 'vertex-stuff', with\n",
      "this location and job_type. Please delete the existing assignment first.\",\n",
      "'status': 'ALREADY_EXISTS'}}\n"
     ]
    }
   ],
   "source": [
    "RESERVATION = 'default'\n",
    "SLOTS=10\n",
    "CC_SLOTS = 100\n",
    "RESERVATION_ID = PROJECT_ID + \":\" + BQ_REGION + \".\" + RESERVATION\n",
    "!gcloud services enable bigqueryreservation.googleapis.com\n",
    "!bq mk --project_id=$PROJECT_ID  --location=$BQ_REGION --capacity_commitment --slots=$CC_SLOTS --plan=FLEX\n",
    "!bq mk --reservation --project_id=$PROJECT_ID --slots=$SLOTS --location=$BQ_REGION $RESERVATION\n",
    "!bq mk --reservation_assignment --reservation_id=$RESERVATION_ID --job_type=QUERY --assignee_type=PROJECT --assignee_id=$PROJECT_ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "qc5rdQap8p1z"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Query complete after 0.00s: 100%|██████████| 1/1 [00:00<00:00, 1062.93query/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: []"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%bigquery --project $PROJECT_ID --params $params\n",
    "declare dataset STRING;\n",
    "set dataset = @dataset;\n",
    "EXECUTE IMMEDIATE CONCAT('CREATE MODEL IF NOT EXISTS ', dataset, '''.item_matching_model\n",
    "OPTIONS(\n",
    "    MODEL_TYPE='matrix_factorization', \n",
    "    USER_COL='item1_Id', \n",
    "    ITEM_COL='item2_Id',\n",
    "    RATING_COL='score'\n",
    ")\n",
    "AS\n",
    "SELECT 0 AS item1_Id, 0 AS item2_Id, 0 AS score''');\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-W2Rajhs8p1z"
   },
   "source": [
    "## Create the stored procedures\r\n",
    "\r\n",
    "Run the scripts that create the BigQuery stored procedures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "Cp87zCIu8p10"
   },
   "outputs": [],
   "source": [
    "client = bigquery.Client(project=PROJECT_ID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "VKXjLIqU8p11"
   },
   "outputs": [],
   "source": [
    "sql_scripts = dict()\n",
    "\n",
    "for script_file in [file for file in os.listdir(SQL_SCRIPTS_DIR) if '.sql' in file]:\n",
    "  script_file_path = os.path.join(SQL_SCRIPTS_DIR, script_file)\n",
    "  sql_script = open(script_file_path, 'r').read()\n",
    "  sql_script = sql_script.replace('@DATASET_NAME', BQ_DATASET_NAME)\n",
    "  sql_scripts[script_file] = sql_script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "mHq4rJYf8p12"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executing sp_ExractEmbeddings.sql script...\n",
      "Executing sp_TrainItemMatchingModel.sql script...\n",
      "Executing sp_ComputePMI.sql script...\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "for script_file in sql_scripts:\n",
    "  print(f'Executing {script_file} script...')\n",
    "  query = sql_scripts[script_file]\n",
    "  query_job = client.query(query)\n",
    "  result = query_job.result()\n",
    "\n",
    "print('Done.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copying file://sql_scripts/sp_ExractEmbeddings.sql [Content-Type=application/x-sql]...\n",
      "Copying file://sql_scripts/sp_TrainItemMatchingModel.sql [Content-Type=application/x-sql]...\n",
      "Copying file://sql_scripts/sp_ComputePMI.sql [Content-Type=application/x-sql]...\n",
      "/ [3 files][  3.8 KiB/  3.8 KiB]                                                \n",
      "Operation completed over 3 objects/3.8 KiB.                                      \n"
     ]
    }
   ],
   "source": [
    "### Move the sql scripts to the a bucket for later usage in the pipelines\n",
    "\n",
    "!gsutil cp -r sql_scripts/ 'gs://{BUCKET}/sql_scripts'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1a3kqq5Q8p12"
   },
   "source": [
    "### List the stored procedures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "Jm5crAur8p13"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>specific_catalog</th>\n",
       "      <th>specific_schema</th>\n",
       "      <th>specific_name</th>\n",
       "      <th>routine_catalog</th>\n",
       "      <th>routine_schema</th>\n",
       "      <th>routine_name</th>\n",
       "      <th>routine_type</th>\n",
       "      <th>data_type</th>\n",
       "      <th>routine_body</th>\n",
       "      <th>routine_definition</th>\n",
       "      <th>external_language</th>\n",
       "      <th>is_deterministic</th>\n",
       "      <th>security_type</th>\n",
       "      <th>created</th>\n",
       "      <th>last_altered</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>vertex-stuff</td>\n",
       "      <td>css_retail</td>\n",
       "      <td>sp_ExractEmbeddings</td>\n",
       "      <td>vertex-stuff</td>\n",
       "      <td>css_retail</td>\n",
       "      <td>sp_ExractEmbeddings</td>\n",
       "      <td>PROCEDURE</td>\n",
       "      <td>None</td>\n",
       "      <td>SQL</td>\n",
       "      <td>BEGIN\\n  CREATE OR REPLACE TABLE  css_retail.i...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>2021-09-30 20:59:26.637000+00:00</td>\n",
       "      <td>2021-09-30 20:59:26.637000+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>vertex-stuff</td>\n",
       "      <td>css_retail</td>\n",
       "      <td>sp_TrainItemMatchingModel</td>\n",
       "      <td>vertex-stuff</td>\n",
       "      <td>css_retail</td>\n",
       "      <td>sp_TrainItemMatchingModel</td>\n",
       "      <td>PROCEDURE</td>\n",
       "      <td>None</td>\n",
       "      <td>SQL</td>\n",
       "      <td>BEGIN\\n\\n  CREATE OR REPLACE MODEL css_retail....</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>2021-09-30 20:59:27.916000+00:00</td>\n",
       "      <td>2021-09-30 20:59:27.916000+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>vertex-stuff</td>\n",
       "      <td>css_retail</td>\n",
       "      <td>sp_ComputePMI</td>\n",
       "      <td>vertex-stuff</td>\n",
       "      <td>css_retail</td>\n",
       "      <td>sp_ComputePMI</td>\n",
       "      <td>PROCEDURE</td>\n",
       "      <td>None</td>\n",
       "      <td>SQL</td>\n",
       "      <td>BEGIN\\n\\n  DECLARE total INT64;\\n\\n  # Get ite...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>2021-09-30 20:59:29.418000+00:00</td>\n",
       "      <td>2021-09-30 20:59:29.418000+00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  specific_catalog specific_schema              specific_name routine_catalog  \\\n",
       "0     vertex-stuff      css_retail        sp_ExractEmbeddings    vertex-stuff   \n",
       "1     vertex-stuff      css_retail  sp_TrainItemMatchingModel    vertex-stuff   \n",
       "2     vertex-stuff      css_retail              sp_ComputePMI    vertex-stuff   \n",
       "\n",
       "  routine_schema               routine_name routine_type data_type  \\\n",
       "0     css_retail        sp_ExractEmbeddings    PROCEDURE      None   \n",
       "1     css_retail  sp_TrainItemMatchingModel    PROCEDURE      None   \n",
       "2     css_retail              sp_ComputePMI    PROCEDURE      None   \n",
       "\n",
       "  routine_body                                 routine_definition  \\\n",
       "0          SQL  BEGIN\\n  CREATE OR REPLACE TABLE  css_retail.i...   \n",
       "1          SQL  BEGIN\\n\\n  CREATE OR REPLACE MODEL css_retail....   \n",
       "2          SQL  BEGIN\\n\\n  DECLARE total INT64;\\n\\n  # Get ite...   \n",
       "\n",
       "  external_language is_deterministic security_type  \\\n",
       "0              None             None          None   \n",
       "1              None             None          None   \n",
       "2              None             None          None   \n",
       "\n",
       "                           created                     last_altered  \n",
       "0 2021-09-30 20:59:26.637000+00:00 2021-09-30 20:59:26.637000+00:00  \n",
       "1 2021-09-30 20:59:27.916000+00:00 2021-09-30 20:59:27.916000+00:00  \n",
       "2 2021-09-30 20:59:29.418000+00:00 2021-09-30 20:59:29.418000+00:00  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = f'SELECT * FROM {BQ_DATASET_NAME}.INFORMATION_SCHEMA.ROUTINES;'\n",
    "query_job = client.query(query)\n",
    "query_job.result().to_dataframe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qeJmhunE961u"
   },
   "source": [
    "You can also verify that the stored procedures have been created by viewing them in the [BigQuery console](https://pantheon.corp.google.com/bigquery).\r\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mxd9Wvpi8p13"
   },
   "source": [
    "## License\n",
    "\n",
    "Copyright 2020 Google LLC\n",
    "\n",
    "Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "you may not use this file except in compliance with the License. You may obtain a copy of the License at: http://www.apache.org/licenses/LICENSE-2.0\n",
    "\n",
    "Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. \n",
    "\n",
    "See the License for the specific language governing permissions and limitations under the License.\n",
    "\n",
    "**This is not an official Google product but sample code provided for an educational purpose**"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "00_prep_bq_procedures.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "environment": {
   "name": "tf2-gpu.2-6.m79",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-6:m79"
  },
  "kernelspec": {
   "display_name": "Python [conda env:root] *",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
