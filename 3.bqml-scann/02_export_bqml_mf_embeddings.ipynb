{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dkgce5cdOcW7"
   },
   "source": [
    "# Part 2: Process the item embedding data in BigQuery and export it to Cloud Storage\n",
    "\n",
    "This notebook is the second of five notebooks that guide you through running the [Real-time Item-to-item Recommendation with BigQuery ML Matrix Factorization and ScaNN](https://github.com/GoogleCloudPlatform/analytics-componentized-patterns/tree/master/retail/recommendation-system/bqml-scann) solution.\n",
    "\n",
    "Use this notebook to complete the following tasks:\n",
    "\n",
    "1. Process the product embeddings data in BigQuery to generate a single embedding vector for each song.\n",
    "1. Use a Dataflow pipeline to write the embedding vector data to CSV files and export the files to a Cloud Storage bucket. \n",
    "\n",
    "Before starting this notebook, you must run the [01_train_bqml_mf_pmi](01_train_bqml_mf_pmi.ipynb) notebook to calculate item PMI data and then train a matrix factorization model with it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SW1RHsqGPNzE"
   },
   "source": [
    "## Setup\r\n",
    "\r\n",
    "Import the required libraries, configure the environment variables, and authenticate your GCP account.\r\n",
    "\r\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zdSKSzqvR_qY"
   },
   "source": [
    "### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "OcUKzLnuR_wa"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import apache_beam as beam\n",
    "from datetime import datetime\n",
    "from google.cloud import storage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "22rDpO3JPcy9"
   },
   "source": [
    "### Configure GCP environment settings\r\n",
    "\r\n",
    "Update the following variables to reflect the values for your GCP environment:\r\n",
    "\r\n",
    "+ `PROJECT_ID`: The ID of the Google Cloud project you are using to implement this solution.\r\n",
    "+ `BUCKET`: The name of the Cloud Storage bucket you created to use with this solution. The `BUCKET` value should be just the bucket name, so `myBucket` rather than `gs://myBucket`.\r\n",
    "+ `REGION`: The region to use for the Dataflow job."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "Nyx4vEd7Oa9I"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated property [core/project].\n"
     ]
    }
   ],
   "source": [
    "PROJECT_ID = 'vertex-stuff' # Change to your project.\n",
    "BUCKET = 'jsw-matching-engine' # Change to the bucket you created.\n",
    "REGION = 'us-central1'\n",
    "BQ_DATASET_NAME = 'css_retail'\n",
    "\n",
    "!gcloud config set project $PROJECT_ID"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3d89ZwydPhQX"
   },
   "source": [
    "### Authenticate your GCP account\n",
    "This is required if you run the notebook in Colab. If you use an AI Platform notebook, you should already be authenticated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "6ICvdRicPhl8"
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    from google.colab import auth\n",
    "    auth.authenticate_user()\n",
    "    print(\"Colab user is authenticated.\")\n",
    "except: pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "R1gmEmHbSaQD"
   },
   "source": [
    "## Process the item embeddings data\r\n",
    "\r\n",
    "You run the [sp_ExractEmbeddings](sql_scripts/sp_ExractEmbeddings.sql) stored procedure to process the item embeddings data and write the results to the `item_embeddings` table.\r\n",
    "\r\n",
    "This stored procedure works as follows:\r\n",
    "\r\n",
    "1. Uses the [ML.WEIGHTS](https://cloud.google.com/bigquery-ml/docs/reference/standard-sql/bigqueryml-syntax-weights) function to extract the item embedding matrices from the `item_matching_model` model.\r\n",
    "1. Aggregates these matrices to generate a single embedding vector for each item.\r\n",
    "\r\n",
    "    Because BigQuery ML matrix factorization models are designed for user-item recommendation use cases, they generate two embedding matrices, one for users, and the other of items. However, in this use case, both embedding matrices represent items, but in different axes of the feedback matrix. For more information about how the feedback matrix is calculated, see [Understanding item embeddings](https://cloud.google.com/solutions/real-time-item-matching#understanding_item_embeddings).\r\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "utkyuwJUyTlb"
   },
   "source": [
    "### Run the `sp_ExractEmbeddings` stored procedure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "params = {\"dataset\" : BQ_DATASET_NAME}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "DK0olptba8qi"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Query complete after 0.00s: 100%|██████████| 1/1 [00:00<00:00, 1021.51query/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: []"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%bigquery --project $PROJECT_ID --params $params\n",
    "\n",
    "CALL css_retail.sp_ExractEmbeddings() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0UvHD7BJ8Gk0"
   },
   "source": [
    "Get a count of the records in the `item_embeddings` table:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "pQsJenNFzVJ7"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Query complete after 0.00s: 100%|██████████| 2/2 [00:00<00:00, 1082.40query/s]                        \n",
      "Downloading: 100%|██████████| 1/1 [00:00<00:00,  1.02rows/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>embedding_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2933</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   embedding_count\n",
       "0             2933"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%bigquery --project $PROJECT_ID\n",
    "\n",
    "SELECT COUNT(*) embedding_count\n",
    "FROM css_retail.item_embeddings;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sx8JNJbA8PxC"
   },
   "source": [
    "See a sample of the data in the `item_embeddings` table:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "Y4kTGcaRzVJ7"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Query complete after 0.00s: 100%|██████████| 1/1 [00:00<00:00, 540.57query/s]                          \n",
      "Downloading: 100%|██████████| 5/5 [00:00<00:00,  5.83rows/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>item_Id</th>\n",
       "      <th>embedding</th>\n",
       "      <th>bias</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2565</td>\n",
       "      <td>[-1.7000731697684879, 4.32766909722082, -8.684...</td>\n",
       "      <td>0.296106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>23047</td>\n",
       "      <td>[-16.45777759001077, 14.336397805487517, -2.60...</td>\n",
       "      <td>-0.399879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4363</td>\n",
       "      <td>[-0.22027002165007695, 4.4951353161154834, -8....</td>\n",
       "      <td>1.326860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7182</td>\n",
       "      <td>[-2.699671782372556, -0.7021591058614676, -10....</td>\n",
       "      <td>-0.605113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>16404</td>\n",
       "      <td>[0.22598407970649526, 6.216626707381438, 0.529...</td>\n",
       "      <td>0.318354</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  item_Id                                          embedding      bias\n",
       "0    2565  [-1.7000731697684879, 4.32766909722082, -8.684...  0.296106\n",
       "1   23047  [-16.45777759001077, 14.336397805487517, -2.60... -0.399879\n",
       "2    4363  [-0.22027002165007695, 4.4951353161154834, -8....  1.326860\n",
       "3    7182  [-2.699671782372556, -0.7021591058614676, -10.... -0.605113\n",
       "4   16404  [0.22598407970649526, 6.216626707381438, 0.529...  0.318354"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%bigquery --project $PROJECT_ID\n",
    "\n",
    "SELECT *\n",
    "FROM css_retail.item_embeddings\n",
    "LIMIT 5;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i3LKaxlNSkrv"
   },
   "source": [
    "## Export the item embedding vector data\n",
    "\n",
    "Export the item embedding data to Cloud Storage by using a Dataflow pipeline. This pipeline does the following:\n",
    "\n",
    "1. Reads the item embedding records from the `item_embeddings` table in BigQuery.\n",
    "1. Writes each item embedding record to a CSV file.\n",
    "1. Writes the item embedding CSV files to a Cloud Storage bucket.\n",
    "\n",
    "The pipeline in implemented in the [embeddings_exporter/pipeline.py](embeddings_exporter/pipeline.py) module."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "G8HLFGGl5oac"
   },
   "source": [
    "### Configure the pipeline variables\r\n",
    "\r\n",
    "Configure the variables needed by the pipeline:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "2ZKaoBwnSk6U"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "runner: DataflowRunner\n",
      "job_name: ks-bqml-export-embeddings-210930213013\n",
      "bq_dataset_name: css_retail\n",
      "embeddings_table_name: item_embeddings\n",
      "output_dir: gs://jsw-matching-engine/bqml/item_embeddings\n",
      "project: vertex-stuff\n",
      "temp_location: gs://jsw-matching-engine/bqml/item_embeddings/tmp\n",
      "region: us-central1\n"
     ]
    }
   ],
   "source": [
    "runner = 'DataflowRunner'\n",
    "timestamp = datetime.utcnow().strftime('%y%m%d%H%M%S')\n",
    "job_name = f'ks-bqml-export-embeddings-{timestamp}'\n",
    "bq_dataset_name = BQ_DATASET_NAME\n",
    "embeddings_table_name = 'item_embeddings'\n",
    "output_dir = f'gs://{BUCKET}/bqml/item_embeddings'\n",
    "project = PROJECT_ID\n",
    "temp_location = os.path.join(output_dir, 'tmp')\n",
    "region = REGION\n",
    "\n",
    "print(f'runner: {runner}')\n",
    "print(f'job_name: {job_name}')\n",
    "print(f'bq_dataset_name: {bq_dataset_name}')\n",
    "print(f'embeddings_table_name: {embeddings_table_name}')\n",
    "print(f'output_dir: {output_dir}')\n",
    "print(f'project: {project}')\n",
    "print(f'temp_location: {temp_location}')\n",
    "print(f'region: {region}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "OyiIh-ATzVJ8"
   },
   "outputs": [],
   "source": [
    "try: os.chdir(os.path.join(os.getcwd(), 'embeddings_exporter'))\n",
    "except: pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AHxODaoFzVJ8"
   },
   "source": [
    "### Run the pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OBarPrE_-LJr"
   },
   "source": [
    "It takes about 5 minutes to run the pipeline. You can see the graph for the running pipeline in the [Dataflow Console](https://console.cloud.google.com/dataflow/jobs)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def export_embeddings_pipeline(args):\n",
    "\n",
    "    pipeline_options = beam.options.pipeline_options.PipelineOptions(**args)\n",
    "    with beam.Pipeline(options=pipeline_options) as p:\n",
    "        def get_query(dataset_name, table_name):\n",
    "            query = f'''\n",
    "            SELECT \n",
    "                item_Id,\n",
    "                embedding\n",
    "            FROM \n",
    "                `{dataset_name}.{table_name}`;\n",
    "            '''\n",
    "            return query\n",
    "\n",
    "        def to_csv(entry):\n",
    "            item_Id = entry['item_Id']\n",
    "            embedding = entry['embedding']\n",
    "            csv_string = f'{item_Id},'\n",
    "            csv_string += ','.join([str(value) for value in embedding])\n",
    "            return csv_string\n",
    "\n",
    "        query = get_query(BQ_DATASET_NAME, embeddings_table_name)\n",
    "        output_prefix = os.path.join(output_dir, 'embeddings')\n",
    "            \n",
    "        _ = (\n",
    "            p\n",
    "            | 'ReadFromBigQuery' >> beam.io.ReadFromBigQuery(\n",
    "                project=PROJECT_ID, query=query, use_standard_sql=True, flatten_results=False)\n",
    "            | 'ConvertToCsv' >> beam.Map(to_csv)\n",
    "            | 'WriteToCloudStorage' >> beam.io.WriteToText(\n",
    "                file_path_prefix = output_prefix,\n",
    "                file_name_suffix = \".csv\")\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline args are set.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "RUNNER = 'DataflowRunner'\n",
    "\n",
    "job_name = f'extract-embeddings-{datetime.utcnow().strftime(\"%y%m%d%H%M%S\")}'\n",
    "\n",
    "args = {\n",
    "    'job_name': job_name,\n",
    "    'runner': RUNNER,\n",
    "    'project': PROJECT_ID,\n",
    "    'temp_location': f'gs://{BUCKET}/dataflow_tmp',\n",
    "    'region': REGION\n",
    "}\n",
    "\n",
    "print(\"Pipeline args are set.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WngoWnt2zVJ9"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:apache_beam.runners.interactive.interactive_environment:Dependencies required for Interactive Beam PCollection visualization are not available, please use: `pip install apache-beam[interactive]` to install necessary dependencies to enable all data visualization features.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running pipeline...\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "        if (typeof window.interactive_beam_jquery == 'undefined') {\n",
       "          var jqueryScript = document.createElement('script');\n",
       "          jqueryScript.src = 'https://code.jquery.com/jquery-3.4.1.slim.min.js';\n",
       "          jqueryScript.type = 'text/javascript';\n",
       "          jqueryScript.onload = function() {\n",
       "            var datatableScript = document.createElement('script');\n",
       "            datatableScript.src = 'https://cdn.datatables.net/1.10.20/js/jquery.dataTables.min.js';\n",
       "            datatableScript.type = 'text/javascript';\n",
       "            datatableScript.onload = function() {\n",
       "              window.interactive_beam_jquery = jQuery.noConflict(true);\n",
       "              window.interactive_beam_jquery(document).ready(function($){\n",
       "                \n",
       "              });\n",
       "            }\n",
       "            document.head.appendChild(datatableScript);\n",
       "          };\n",
       "          document.head.appendChild(jqueryScript);\n",
       "        } else {\n",
       "          window.interactive_beam_jquery(document).ready(function($){\n",
       "            \n",
       "          });\n",
       "        }"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/apache_beam/io/gcp/bigquery.py:1929: BeamDeprecationWarning: options is deprecated since First stable release. References to <pipeline>.options will not be supported\n",
      "  temp_location = pcoll.pipeline.options.view_as(\n",
      "WARNING:root:Make sure that locally built Python SDK docker image has Python 3.7 interpreter.\n",
      "WARNING:apache_beam.options.pipeline_options:Discarding unparseable args: ['-f', '/home/jupyter/.local/share/jupyter/runtime/kernel-e8b74c49-d9d2-4426-bf3b-f6d3c17971f1.json']\n",
      "WARNING:apache_beam.options.pipeline_options:Discarding unparseable args: ['-f', '/home/jupyter/.local/share/jupyter/runtime/kernel-e8b74c49-d9d2-4426-bf3b-f6d3c17971f1.json']\n"
     ]
    }
   ],
   "source": [
    "print(\"Running pipeline...\")\n",
    "%time export_embeddings_pipeline(args)\n",
    "print(\"Pipeline is done.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PLXGq4CA_Oz0"
   },
   "source": [
    "### List the CSV files that were written to Cloud Storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ee89jHK5zVJ9"
   },
   "outputs": [],
   "source": [
    "!gsutil ls {output_dir}/embeddings-*.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Fp1bOyVCgBnH"
   },
   "source": [
    "## License\n",
    "\n",
    "Copyright 2020 Google LLC\n",
    "\n",
    "Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "you may not use this file except in compliance with the License. You may obtain a copy of the License at: http://www.apache.org/licenses/LICENSE-2.0\n",
    "\n",
    "Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. \n",
    "\n",
    "See the License for the specific language governing permissions and limitations under the License.\n",
    "\n",
    "**This is not an official Google product but sample code provided for an educational purpose**"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "02_export_bqml_mf_embeddings.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "environment": {
   "name": "tf2-gpu.2-6.m79",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-6:m79"
  },
  "kernelspec": {
   "display_name": "Python [conda env:root] *",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
