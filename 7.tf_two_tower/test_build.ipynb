{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "66eba3fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "\n",
    "from absl import app\n",
    "from absl import flags\n",
    "from absl import logging\n",
    "\n",
    "import tensorflow\n",
    "\n",
    "from google.cloud import aiplatform as vertex_ai\n",
    "from google.cloud import bigquery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "06bac21f",
   "metadata": {},
   "outputs": [],
   "source": [
    "PREFIX = 'two-tower' \n",
    "PREFIX = 'css_retail'\n",
    "DISPLAY_NAME = f'{PREFIX}-tensorboard'\n",
    "PROJECT= 'babrams-recai-demo-final'\n",
    "REGION='us-central1'\n",
    "\n",
    "STAGING_BUCKET = \"\"\"gs://{}_vertex_training\"\"\".format(PROJECT) #lowes-reccomendation-tensorboard-logs-us-central1 - this \n",
    "#TENSORBOARD = 'projects/258043323883/locations/us-central1/tensorboards/4236655796332527616' #note really can only get this after gcloud beta ai tensorboards create...\n",
    "#VERTEX_SA = 'vertex-tb@lowes-reccomendation.iam.gserviceaccount.com'\n",
    "\n",
    "# initialize vertex sdk\n",
    "vertex_ai.init(\n",
    "    project=PROJECT,\n",
    "    location=REGION,\n",
    "    staging_bucket=STAGING_BUCKET\n",
    ")\n",
    "\n",
    "client = bigquery.Client()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "a308490d",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow_recommenders'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_30874/3715321153.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtensorflow_recommenders\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtfrs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mabsl\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mapp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow_recommenders'"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import tensorflow as tf\n",
    "import tensorflow_recommenders as tfrs\n",
    "import os\n",
    "from absl import app\n",
    "from absl import flags\n",
    "from absl import logging\n",
    "from google.cloud import storage\n",
    "\n",
    "FLAGS = flags.FLAGS\n",
    "flags.DEFINE_float(\"LR\", 0.01, \"Learning Rate\")\n",
    "flags.DEFINE_integer(\"EMBEDDING_DIM\", 16, \"Embedding dimension\")\n",
    "flags.DEFINE_integer(\"MAX_TOKENS\", 16, \"Max embeddings for query and last_n products\")\n",
    "flags.DEFINE_integer(\"NUM_EPOCHS\", 30, \"Number of epochs\")\n",
    "flags.DEFINE_string(\"MODEL_DIR\", 'model-dirs-lowes', \"GCS Bucket to store the model artifact\")\n",
    "flags.DEFINE_bool(\"DROPOUT\", False, \"Use Dropout - T/F bool type\")\n",
    "flags.DEFINE_float(\"DROPOUT_RATE\", 0.4, \"Dropout rate only works with DROPOUT=True\")\n",
    "flags.DEFINE_integer(\"N_PRODUCTS\", 20000, \"number of products considered for embedding\")\n",
    "flags.DEFINE_integer(\"BATCH_SIZE\", 1024, \"batch size\")\n",
    "flags.DEFINE_string(\"ARCH\", '[128,64]', \"deep architecture, expressed as a list of ints in string format - will be parsed into list\")\n",
    "flags.DEFINE_integer(\"SEED\", 41781897, \"random seed\")\n",
    "flags.DEFINE_string(\"TF_RECORDS_DIR\", \"gs://tfrs-central-a\", \"source data in tfrecord format gcs location\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "ce7e3d7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>productId</th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>29120.000000</td>\n",
       "      <td>29120.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>14560.500000</td>\n",
       "      <td>28.481775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>8406.364256</td>\n",
       "      <td>30.624681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.008300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>7280.750000</td>\n",
       "      <td>11.275650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>14560.500000</td>\n",
       "      <td>19.675100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>21840.250000</td>\n",
       "      <td>34.440000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>29120.000000</td>\n",
       "      <td>557.151000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          productId         price\n",
       "count  29120.000000  29120.000000\n",
       "mean   14560.500000     28.481775\n",
       "std     8406.364256     30.624681\n",
       "min        1.000000      0.008300\n",
       "25%     7280.750000     11.275650\n",
       "50%    14560.500000     19.675100\n",
       "75%    21840.250000     34.440000\n",
       "max    29120.000000    557.151000"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "product_catalog_sql = \"\"\"\n",
    "with inner_q as (\n",
    "    select \n",
    "        cast(id as int) as productId,\n",
    "        title,\n",
    "        description,\n",
    "        product_metadata.exact_price.original_price as price,\n",
    "        array_to_string(cats.categories, '|') as categories\n",
    "    from `babrams-recai-demo-final.css_retail.recommendation_ai_data` as rad\n",
    "    , unnest(category_hierarchies) as cats\n",
    ") select \n",
    "    productId,\n",
    "    title,\n",
    "    description,\n",
    "    price,\n",
    "    array_to_string(array_agg(categories), \",\") as categories\n",
    "from inner_q \n",
    "group by productId, title, description, price\n",
    "\"\"\"\n",
    "\n",
    "product_catalog_df = client.query(product_catalog_sql).to_dataframe()\n",
    "product_catalog_df.describe()\n",
    "product_categoricals = ['productId', 'title', 'description', 'categories']\n",
    "# product_catalog_df.dtypes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "e52b1aef",
   "metadata": {},
   "outputs": [],
   "source": [
    "genders = {'Male': 0, 'Female': 1}\n",
    "def gender_map(gender):\n",
    "    return genders[gender] if gender in genders else -1\n",
    "    \n",
    "traffic_sources = {'Organic': 0, 'Email': 1, 'Search': 2, 'Facebook': 3, 'Display': 4}\n",
    "def traffic_source_map(traffic_source):\n",
    "    return traffic_sources[traffic_source] if traffic_source in traffic_sources else -1\n",
    "    \n",
    "customer_data_sql = \"\"\"\n",
    "select\n",
    "    id as userId,\n",
    "    age,\n",
    "    gender,\n",
    "    latitude,\n",
    "    longitude,\n",
    "    traffic_source,\n",
    "    TIMESTAMP_DIFF(CURRENT_TIMESTAMP(), created_at, DAY) as customer_lifetime_days\n",
    "from `babrams-recai-demo-final.css_retail.customers` as customers\n",
    "\"\"\"\n",
    "customer_data = client.query(customer_data_sql)\n",
    "customer_data_df = customer_data.to_dataframe()\n",
    "customer_data_df.describe()\n",
    "customer_categoricals = ['userId', 'gender', 'traffic_source']\n",
    "\n",
    "#customer_tf = \n",
    "#customer_data_df['gender'] = customer_data_df['gender'].apply(gender_map)\n",
    "#customer_data_df['traffic_source'] = customer_data_df['traffic_source'].apply(traffic_source_map)\n",
    "#customer_data_df.describe()\n",
    "#customer_data_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "af46a1dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "purchase_data_sql = \"\"\"\n",
    "select\n",
    "    cast(userInfo.userId as int) as userId, \n",
    "    unix_millis(safe_cast(eventTime as timestamp)) as eventTime,\n",
    "    productEventDetail.cartId,\n",
    "    productEventDetail.purchaseTransaction.revenue,\n",
    "    products.id as productId,\n",
    "    products.quantity,\n",
    "    products.displayPrice as price\n",
    "from `babrams-recai-demo-final.css_retail.purchase_complete` as purchase\n",
    ", UNNEST(productEventDetail.productDetails) products\n",
    "\"\"\"\n",
    "\n",
    "purchase_data_df = client.query(purchase_data_sql).to_dataframe()\n",
    "purchase_data_df.describe()\n",
    "purchase_categoricals = ['userId', 'cartId', 'productId']\n",
    "# purchase_data_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "46c98931",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(323423, 7), dtype=float64, numpy=\n",
       "array([[2.99000000e+04, 1.61845640e+12,            nan, ...,\n",
       "        1.36060000e+04, 1.00000000e+00,            nan],\n",
       "       [7.83180000e+04, 1.61041771e+12,            nan, ...,\n",
       "        1.36060000e+04, 1.00000000e+00,            nan],\n",
       "       [3.06130000e+04, 1.61086903e+12,            nan, ...,\n",
       "        1.36060000e+04, 1.00000000e+00,            nan],\n",
       "       ...,\n",
       "       [1.72260000e+04, 1.64057820e+12,            nan, ...,\n",
       "        3.69000000e+02, 1.00000000e+00,            nan],\n",
       "       [1.72260000e+04, 1.64057820e+12,            nan, ...,\n",
       "        1.87000000e+02, 1.00000000e+00,            nan],\n",
       "       [1.72260000e+04, 1.64057820e+12,            nan, ...,\n",
       "        3.69000000e+02, 1.00000000e+00,            nan]])>"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#customers_tf = tensorflow.convert_to_tensor(customer_data_df)\n",
    "#purchase_tf = tensorflow.convert_to_tensor(purchase_data_df)\n",
    "\n",
    "class ProductModel(tf.keras.Model):\n",
    "    def __init__(self, layer_sizes, adapt_data):\n",
    "        super().__init__()\n",
    "\n",
    "        #categorical with vocabs\n",
    "        #pr_vocab = tf.constant(['002_$100 - $299', '000_$0 - $49', '001_$50 - $99', \n",
    "        #            '003_$300 - $599', '005_$1000 - $3999', '004_$600 - $999', \n",
    "        #            '006_$4000+', ''])\n",
    "\n",
    "        #self.price_range_embedding = tf.keras.Sequential([\n",
    "        #    tf.keras.layers.StringLookup(\n",
    "        #          vocabulary=pr_vocab, mask_token=None, name=\"price_range_lu\", output_mode='count')\n",
    "        #], name=\"price_range_embedding\")\n",
    "        \n",
    "        # categorical: description - below are all embeddings with unk vocabs - will be adapted \n",
    "        self.description_vectorizor = tf.keras.layers.TextVectorization(\n",
    "            max_tokens=FLAGS.N_PRODUCTS\n",
    "            , name = \"description_vectorizor\"\n",
    "        )\n",
    "\n",
    "        self.description_embedding = tf.keras.Sequential(\n",
    "            [\n",
    "                self.description_vectorizor,\n",
    "                tf.keras.layers.Embedding(\n",
    "                    FLAGS.N_PRODUCTS+1, \n",
    "                    FLAGS.EMBEDDING_DIM, \n",
    "                    mask_zero=True, \n",
    "                    name = \"desc_emb\"),\n",
    "                tf.keras.layers.GlobalAveragePooling1D(\n",
    "                    name=\"desc_flatten\"\n",
    "                )\n",
    "            ], \n",
    "            name=\"description_embedding\"\n",
    "        )\n",
    "        \n",
    "        #categorical: sku\n",
    "        self.sku_vectorizor = tf.keras.layers.TextVectorization(\n",
    "            max_tokens=FLAGS.N_PRODUCTS, name = \"sku_vectorizor\")\n",
    "\n",
    "        self.sku_embedding = tf.keras.Sequential([\n",
    "            self.sku_vectorizor,\n",
    "            tf.keras.layers.Embedding(FLAGS.N_PRODUCTS+1, FLAGS.EMBEDDING_DIM, mask_zero=True, name = \"sku_emb\"),\n",
    "            tf.keras.layers.GlobalAveragePooling1D(name=\"sku_flat\")\n",
    "        ], name=\"sku_embedding\")\n",
    "        \n",
    "        \n",
    "        ## prod hierarcy\n",
    "#         def split_fn(string):\n",
    "#             return tf.strings.split(string, sep=\"|\")\n",
    "\n",
    "#         self.prod_hier_vectorizor = tf.keras.layers.TextVectorization(\n",
    "#             max_tokens=N_HIER, split=split_fn, name = \"hier_vectorizor\")\n",
    "#         #54724 - count unique\n",
    "#         self.hier_embedding = tf.keras.Sequential([\n",
    "#             self.prod_hier_vectorizor,\n",
    "#             tf.keras.layers.Embedding(N_HIER+1, EMBEDDING_DIM, mask_zero=True, name = \"hier_emb\"),\n",
    "#             tf.keras.layers.GlobalAveragePooling1D(name=\"hier_flat\")\n",
    "#         ], name=\"prod_hier\")\n",
    "        \n",
    "        # Then construct the layers.\n",
    "        self.dense_layers = tf.keras.Sequential(name=\"dense_layers_product\")\n",
    "        \n",
    "        # Adding weight initialzier\n",
    "        initializer = tf.keras.initializers.GlorotUniform(seed=FLAGS.SEED)\n",
    "        # Use the ReLU activation for all but the last layer.\n",
    "        for layer_size in layer_sizes[:-1]:\n",
    "            self.dense_layers.add(tf.keras.layers.Dense(layer_size, activation=\"relu\", kernel_initializer=initializer))\n",
    "            if FLAGS.DROPOUT:\n",
    "                self.dense_layers.add(tf.keras.layers.Dropout(FLAGS.DROPOUT_RATE))\n",
    "            # No activation for the last layer\n",
    "        for layer_size in layer_sizes[-1:]:\n",
    "            self.dense_layers.add(tf.keras.layers.Dense(layer_size, kernel_initializer=initializer))\n",
    "        ### ADDING L2 NORM AT THE END\n",
    "        self.dense_layers.add(tf.keras.layers.Lambda(lambda x: tf.nn.l2_normalize(x, 1, epsilon=1e-12, name=\"normalize_dense\")))\n",
    "        \n",
    "        #adapt stuff\n",
    "#         self.prod_hier_vectorizor.adapt(adapt_data.map(lambda x: x['productTypeCombo_ss']))\n",
    "        self.description_vectorizor.adapt(adapt_data.map(lambda x: x['description']))\n",
    "        self.sku_vectorizor.adapt(adapt_data.map(lambda x: x['IVM_s']))\n",
    "        \n",
    "\n",
    "        \n",
    "        \n",
    "    def call(self, data):\n",
    "        all_embs = tf.concat(\n",
    "            [\n",
    "                tf.reshape(data[\"price_td\"], (-1, 1)),\n",
    "                self.price_range_embedding(data['PriceRange_s']),\n",
    "                self.description_embedding(data['description']),\n",
    "                self.sku_embedding(data['IVM_s']),\n",
    "#                 self.hier_embedding(data['productTypeCombo_ss']),\n",
    "                data['visual']\n",
    "            ], axis=1)\n",
    "        return self.dense_layers(all_embs)  #last plus for number continuous + 1 if you add other(s) 2048 for visual\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "name": "tf2-gpu.2-6.m78",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-6:m78"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
