{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Low-latency item-to-item recommendation system - Creating ANN index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview\n",
    "\n",
    "This notebook is a part of the series that describes the process of implementing a [**Low-latency item-to-item recommendation system**](https://github.com/jarokaz/analytics-componentized-patterns/tree/master/retail/recommendation-system/bqml-scann).\n",
    "\n",
    "The notebook demonstrates how to create and deploy an ANN index using item embeddings created in the preceding notebooks. In this notebook you go through the following steps.\n",
    "\n",
    "1. Exporting embeddings from BigQuery into the JSONL formated file.\n",
    "2. Creating an ANN Index using the exported embeddings.\n",
    "3. Creating and ANN Endpoint. \n",
    "4. Deploying the ANN Index to the ANN Endpoint.\n",
    "5. Testing the deployed ANN Index.\n",
    "\n",
    "This notebook was designed to run on [AI Platform Notebooks](https://cloud.google.com/ai-platform-notebooks). Before running the notebook make sure that you have completed the setup steps as described in the [README file](README.md).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up the notebook's environment\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import notebook dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import base64\n",
    "import datetime\n",
    "import logging\n",
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "import time\n",
    "import sys\n",
    "\n",
    "import grpc\n",
    "\n",
    "import google.auth\n",
    "import numpy as np\n",
    "import tensorflow.io as tf_io\n",
    "\n",
    "from google.cloud import bigquery\n",
    "from typing import List, Optional, Text, Tuple"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the experimental release, the *Online Querying API* of the ANN service is exposed throught the GRPC interface. The `ann_grpc` folder contains the grpc client stub to interface to the API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "ANN_GRPC_ENDPOINT_STUB = 'ann_grpc'\n",
    "if ANN_GRPC_ENDPOINT_STUB not in sys.path:\n",
    "    sys.path.append(ANN_GRPC_ENDPOINT_STUB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ann_grpc.match_pb2_grpc as match_pb2_grpc\n",
    "import ann_grpc.match_pb2 as match_pb2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configure GCP environment\n",
    "\n",
    "Set the following constants to the values reflecting your environment:\n",
    "\n",
    "* `PROJECT_ID` - your GCP project ID.\n",
    "* `PROJECT_NUMBER` - your GCP project number.\n",
    "* `BQ_DATASET_NAME` - the name of the BigQuery dataset that contains the item embeddings table.\n",
    "* `BQ_LOCATION` - the dataset location\n",
    "* `DATA_LOCATION` - a GCS location for the exported embeddings (JSONL) files.\n",
    "* `VPC_NAME` - a name of the GCP VPC to use for the index deployments. Use the name of the VPC prepared during the initial setup. \n",
    "* `REGION` - a compute region. Don't change the default - `us-central` - while the ANN Service is in the experimental stage\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "PROJECT_ID = 'rec-ai-demo-326116' # Change to your project.\n",
    "PROJECT_NUMBER = 733956866731\n",
    "BUCKET = 'rec_bq_jsw' # Change to the bucket you created.\n",
    "BQ_DATASET_NAME = 'css_retail' # <- CHANGE THIS\n",
    "BQ_LOCATION = 'US' # <- CHANGE THIS\n",
    "DATA_LOCATION = f'gs://{BUCKET}/bqml/item_embeddings' # <-CHANGE THIS\n",
    "VPC_NAME = 'default' # <-CHANGE THIS\n",
    "\n",
    "EMBEDDINGS_TABLE = 'item_embeddings'\n",
    "REGION = 'us-central1'\n",
    "MATCH_SERVICE_PORT = 10000\n",
    "PEERING_RANGE_NAME='google-reserved-range'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup the VPC Networking if needed\n",
    "\n",
    "Additional documentation found [here](ann_setup.md)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!gcloud compute addresses create $PEERING_RANGE_NAME \\\n",
    "  --global \\\n",
    "  --prefix-length=16 \\\n",
    "  --description=\"peering range for Google service: AI Platform Online Prediction\" \\\n",
    "  --network=$VPC_NAME \\\n",
    "  --purpose=VPC_PEERING \\\n",
    "  --project=$PROJECT_ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!gcloud services vpc-peerings connect \\\n",
    "  --service=servicenetworking.googleapis.com \\\n",
    "  --network=$VPC_NAME \\\n",
    "  --ranges=$PEERING_RANGE_NAME \\\n",
    "  --project=$PROJECT_ID"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exporting the embeddings\n",
    "\n",
    "In the preceeding notebooks you trained the Matrix Factorization BQML model and exported the embeddings to the `item_embeddings` table. \n",
    "\n",
    "In this step you will extract the embeddings to a set of JSONL files in the format required by the ANN service."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Verify the number of embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = bigquery.Client(project=PROJECT_ID, location=BQ_LOCATION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>embedding_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2933</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   embedding_count\n",
       "0             2933"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = f\"\"\"\n",
    "    SELECT COUNT(*) embedding_count\n",
    "    FROM {BQ_DATASET_NAME}.item_embeddings;\n",
    "\"\"\"\n",
    "\n",
    "query_job = client.query(query)\n",
    "query_job.to_dataframe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Export the embeddings\n",
    "\n",
    "You will use the [BigQuery export job](https://cloud.google.com/bigquery/docs/exporting-data) to export the embeddings table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<google.cloud.bigquery.job.extract.ExtractJob at 0x7fe09b433650>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_name_pattern = 'embedding-*.json'\n",
    "destination_uri = f'{DATA_LOCATION}/{file_name_pattern}'\n",
    "table_id = 'item_embeddings'\n",
    "destination_format = 'NEWLINE_DELIMITED_JSON'\n",
    "\n",
    "dataset_ref = bigquery.DatasetReference(PROJECT_ID, BQ_DATASET_NAME)\n",
    "table_ref = dataset_ref.table(table_id)\n",
    "job_config = bigquery.job.ExtractJobConfig()\n",
    "job_config.destination_format = bigquery.DestinationFormat.NEWLINE_DELIMITED_JSON\n",
    "\n",
    "extract_job = client.extract_table(\n",
    "    table_ref,\n",
    "    destination_uris=destination_uri,\n",
    "    job_config=job_config,\n",
    "    #location=BQ_LOCATION,\n",
    ")  \n",
    "\n",
    "extract_job.result()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inspect the extracted files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gs://rec_bq_jsw/bqml/item_embeddings/\n",
      "gs://rec_bq_jsw/bqml/item_embeddings/embedding-000000000000.json\n",
      "gs://rec_bq_jsw/bqml/item_embeddings/embeddings-00000-of-00001.csv\n",
      "gs://rec_bq_jsw/bqml/item_embeddings/tmp/\n"
     ]
    }
   ],
   "source": [
    "! gsutil ls {DATA_LOCATION}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating an ANN index deployment\n",
    "\n",
    "Deploying an ANN index is a 3 step process:\n",
    "1. Creating an index from source files\n",
    "2. Creating an endpoint to access the index\n",
    "3. Deploying the index to the endpoint\n",
    "\n",
    "\n",
    "You will use the REST interface to invoke the AI Platform ANN Service Control Plane API that manages indexes, endpoints, and deployments.\n",
    "\n",
    "After the index has been deployed you can submit matching requests using Online Querying API. In the experimental stage this API is only accessible through the gRPC interface.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define helper classes to encapsulate the ANN Service REST API.\n",
    "\n",
    "Currently, there is no Python client that encapsulates the ANN Service Control Plane API. The below code snippet defines a simple wrapper that encapsulates a subset of REST APIs used in this notebook.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import logging\n",
    "import json\n",
    "import time\n",
    "\n",
    "import google.auth\n",
    "\n",
    "class ANNClient(object):\n",
    "    \"\"\"Base ANN Service client.\"\"\"\n",
    "    \n",
    "    def __init__(self, project_id, project_number, region):\n",
    "        credentials, _ = google.auth.default()\n",
    "        self.authed_session = google.auth.transport.requests.AuthorizedSession(credentials)\n",
    "        self.ann_endpoint = f'{region}-aiplatform.googleapis.com'\n",
    "        self.ann_parent = f'https://{self.ann_endpoint}/v1alpha1/projects/{project_id}/locations/{region}'\n",
    "        self.project_id = project_id\n",
    "        self.project_number = project_number\n",
    "        self.region = region\n",
    "        \n",
    "    def wait_for_completion(self, operation_id, message, sleep_time):\n",
    "        \"\"\"Waits for a completion of a long running operation.\"\"\"\n",
    "        \n",
    "        api_url = f'{self.ann_parent}/operations/{operation_id}'\n",
    "\n",
    "        start_time = datetime.datetime.utcnow()\n",
    "        while True:\n",
    "            response = self.authed_session.get(api_url)\n",
    "            if response.status_code != 200:\n",
    "                raise RuntimeError(response.json())\n",
    "            if 'done' in response.json().keys():\n",
    "                logging.info('Operation completed!')\n",
    "                break\n",
    "            elapsed_time = datetime.datetime.utcnow() - start_time\n",
    "            logging.info('{}. Elapsed time since start: {}.'.format(\n",
    "                message, str(elapsed_time)))\n",
    "            time.sleep(sleep_time)\n",
    "    \n",
    "        return response.json()\n",
    "\n",
    "\n",
    "class IndexClient(ANNClient):\n",
    "    \"\"\"Encapsulates a subset of control plane APIs \n",
    "    that manage ANN indexes.\"\"\"\n",
    "\n",
    "    def __init__(self, project_id, project_number, region):\n",
    "        super().__init__(project_id, project_number, region)\n",
    "\n",
    "    def create_index(self, display_name, description, metadata):\n",
    "        \"\"\"Creates an ANN Index.\"\"\"\n",
    "    \n",
    "        api_url = f'{self.ann_parent}/indexes'\n",
    "    \n",
    "        request_body = {\n",
    "            'display_name': display_name,\n",
    "            'description': description,\n",
    "            'metadata': metadata\n",
    "        }\n",
    "    \n",
    "        response = self.authed_session.post(api_url, data=json.dumps(request_body))\n",
    "        if response.status_code != 200:\n",
    "            raise RuntimeError(response.text)\n",
    "        operation_id = response.json()['name'].split('/')[-1]\n",
    "        \n",
    "        return operation_id\n",
    "\n",
    "    def list_indexes(self, display_name=None):\n",
    "        \"\"\"Lists all indexes with a given display name or\n",
    "        all indexes if the display_name is not provided.\"\"\"\n",
    "    \n",
    "        if display_name:\n",
    "            api_url = f'{self.ann_parent}/indexes?filter=display_name=\"{display_name}\"'\n",
    "        else:\n",
    "            api_url = f'{self.ann_parent}/indexes'\n",
    "\n",
    "        response = self.authed_session.get(api_url).json()\n",
    "\n",
    "        return response['indexes'] if response else []\n",
    "    \n",
    "    def delete_index(self, index_id):\n",
    "        \"\"\"Deletes an ANN index.\"\"\"\n",
    "        \n",
    "        api_url = f'{self.ann_parent}/indexes/{index_id}'\n",
    "        response = self.authed_session.delete(api_url)\n",
    "        if response.status_code != 200:\n",
    "            raise RuntimeError(response.text)\n",
    "\n",
    "\n",
    "class IndexDeploymentClient(ANNClient):\n",
    "    \"\"\"Encapsulates a subset of control plane APIs \n",
    "    that manage ANN endpoints and deployments.\"\"\"\n",
    "    \n",
    "    def __init__(self, project_id, project_number, region):\n",
    "        super().__init__(project_id, project_number, region)\n",
    "\n",
    "    def create_endpoint(self, display_name, vpc_name):\n",
    "        \"\"\"Creates an ANN endpoint.\"\"\"\n",
    "    \n",
    "        api_url = f'{self.ann_parent}/indexEndpoints'\n",
    "        network_name = f'projects/{self.project_number}/global/networks/{vpc_name}'\n",
    "\n",
    "        request_body = {\n",
    "            'display_name': display_name,\n",
    "            'network': network_name\n",
    "        }\n",
    "\n",
    "        response = self.authed_session.post(api_url, data=json.dumps(request_body))\n",
    "        if response.status_code != 200:\n",
    "            raise RuntimeError(response.text)\n",
    "        operation_id = response.json()['name'].split('/')[-1]\n",
    "    \n",
    "        return operation_id\n",
    "    \n",
    "    def list_endpoints(self, display_name=None):\n",
    "        \"\"\"Lists all ANN endpoints with a given display name or\n",
    "        all endpoints in the project if the display_name is not provided.\"\"\"\n",
    "        \n",
    "        if display_name:\n",
    "            api_url = f'{self.ann_parent}/indexEndpoints?filter=display_name=\"{display_name}\"'\n",
    "        else:\n",
    "            api_url = f'{self.ann_parent}/indexEndpoints'\n",
    "\n",
    "        response = self.authed_session.get(api_url).json()\n",
    " \n",
    "        return response['indexEndpoints'] if response else []\n",
    "    \n",
    "    def delete_endpoint(self, endpoint_id):\n",
    "        \"\"\"Deletes an ANN endpoint.\"\"\"\n",
    "        \n",
    "        api_url = f'{self.ann_parent}/indexEndpoints/{endpoint_id}'\n",
    "        \n",
    "        response = self.authed_session.delete(api_url)\n",
    "        if response.status_code != 200:\n",
    "            raise RuntimeError(response.text)\n",
    "        \n",
    "        return response.json()\n",
    "    \n",
    "    def create_deployment(self, display_name, deployment_id, endpoint_id, index_id):\n",
    "        \"\"\"Deploys an ANN index to an endpoint.\"\"\"\n",
    "    \n",
    "        api_url = f'{self.ann_parent}/indexEndpoints/{endpoint_id}:deployIndex'\n",
    "        index_name = f'projects/{self.project_number}/locations/{self.region}/indexes/{index_id}'\n",
    "\n",
    "        request_body = {\n",
    "            'deployed_index': {\n",
    "                'id': deployment_id,\n",
    "                'index': index_name,\n",
    "                'display_name': display_name\n",
    "            }\n",
    "        }\n",
    "\n",
    "        response = self.authed_session.post(api_url, data=json.dumps(request_body))\n",
    "        if response.status_code != 200:\n",
    "            raise RuntimeError(response.text)\n",
    "        operation_id = response.json()['name'].split('/')[-1]\n",
    "        \n",
    "        return operation_id\n",
    "    \n",
    "    def get_deployment_grpc_ip(self, endpoint_id, deployment_id):\n",
    "        \"\"\"Returns a private IP address for a gRPC interface to \n",
    "        an Index deployment.\"\"\"\n",
    "  \n",
    "        api_url = f'{self.ann_parent}/indexEndpoints/{endpoint_id}'\n",
    "\n",
    "        response = self.authed_session.get(api_url)\n",
    "        if response.status_code != 200:\n",
    "            raise RuntimeError(response.text)\n",
    "            \n",
    "        endpoint_ip = None\n",
    "        if 'deployedIndexes' in response.json().keys():\n",
    "            for deployment in response.json()['deployedIndexes']:\n",
    "                if deployment['id'] == deployment_id:\n",
    "                    endpoint_ip = deployment['privateEndpoints']['matchGrpcAddress']\n",
    "                    \n",
    "        return endpoint_ip\n",
    "\n",
    "    \n",
    "    def delete_deployment(self, endpoint_id, deployment_id):\n",
    "        \"\"\"Undeployes an index from an endpoint.\"\"\"\n",
    "        \n",
    "        api_url = f'{self.ann_parent}/indexEndpoints/{endpoint_id}:undeployIndex'\n",
    "        \n",
    "        request_body = {\n",
    "            'deployed_index_id': deployment_id\n",
    "        }\n",
    "    \n",
    "        response = self.authed_session.post(api_url, data=json.dumps(request_body))\n",
    "        if response.status_code != 200:\n",
    "            raise RuntimeError(response.text)\n",
    "        \n",
    "        return response\n",
    "    \n",
    "index_client = IndexClient(PROJECT_ID, PROJECT_NUMBER, REGION)\n",
    "deployment_client = IndexDeploymentClient(PROJECT_ID, PROJECT_NUMBER, REGION)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create an ANN index\n",
    "\n",
    "#### List all indexes registered with the ANN service"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are not any indexes registered with the service\n"
     ]
    }
   ],
   "source": [
    "indexes = index_client.list_indexes()\n",
    "\n",
    "if not indexes:\n",
    "    print('There are not any indexes registered with the service')\n",
    "\n",
    "for index in indexes:\n",
    "    print(index['name'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Configure and create a new index based on the exported embeddings\n",
    "\n",
    "Index creation is a long running operation. Be patient."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_display_name = 'Product embeddings'\n",
    "index_description = 'Product embeddings created BQML Matrix Factorization model'\n",
    "\n",
    "index_metadata = {\n",
    "    'contents_delta_uri': DATA_LOCATION,\n",
    "    'config': {\n",
    "        'dimensions': 50,\n",
    "        'approximate_neighbors_count': 50,\n",
    "        'distance_measure_type': 'DOT_PRODUCT_DISTANCE',\n",
    "        'feature_norm_type': 'UNIT_L2_NORM',\n",
    "        'tree_ah_config': {\n",
    "            'child_node_count': 1000,\n",
    "            'max_leaves_to_search': 100\n",
    "         }\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Look inside the contents of the `$DATA_LOCATION` bucket - ensure there are no subdirectories and there are either `.json` or `.csv` files (not mixed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Creating index. Elapsed time since start: 0:00:00.078623.\n",
      "INFO:root:Creating index. Elapsed time since start: 0:00:20.164982.\n",
      "INFO:root:Creating index. Elapsed time since start: 0:00:40.278203.\n",
      "INFO:root:Creating index. Elapsed time since start: 0:01:00.414148.\n",
      "INFO:root:Creating index. Elapsed time since start: 0:01:20.514342.\n",
      "INFO:root:Creating index. Elapsed time since start: 0:01:40.581232.\n",
      "INFO:root:Creating index. Elapsed time since start: 0:02:00.652941.\n",
      "INFO:root:Creating index. Elapsed time since start: 0:02:20.762145.\n",
      "INFO:root:Creating index. Elapsed time since start: 0:02:40.847362.\n",
      "INFO:root:Creating index. Elapsed time since start: 0:03:00.918899.\n",
      "INFO:root:Creating index. Elapsed time since start: 0:03:20.980803.\n",
      "INFO:root:Creating index. Elapsed time since start: 0:03:41.124582.\n",
      "INFO:root:Creating index. Elapsed time since start: 0:04:01.208450.\n",
      "INFO:root:Creating index. Elapsed time since start: 0:04:21.275295.\n",
      "INFO:root:Creating index. Elapsed time since start: 0:04:41.345168.\n",
      "INFO:root:Creating index. Elapsed time since start: 0:05:01.431803.\n",
      "INFO:root:Creating index. Elapsed time since start: 0:05:21.488682.\n",
      "INFO:root:Creating index. Elapsed time since start: 0:05:41.567775.\n",
      "INFO:root:Creating index. Elapsed time since start: 0:06:01.653790.\n",
      "INFO:root:Creating index. Elapsed time since start: 0:06:21.763905.\n",
      "INFO:root:Creating index. Elapsed time since start: 0:06:41.853704.\n",
      "INFO:root:Creating index. Elapsed time since start: 0:07:01.928924.\n",
      "INFO:root:Creating index. Elapsed time since start: 0:07:22.024017.\n",
      "INFO:root:Creating index. Elapsed time since start: 0:07:42.109834.\n",
      "INFO:root:Creating index. Elapsed time since start: 0:08:02.229802.\n",
      "INFO:root:Creating index. Elapsed time since start: 0:08:22.292690.\n",
      "INFO:root:Creating index. Elapsed time since start: 0:08:42.413389.\n",
      "INFO:root:Creating index. Elapsed time since start: 0:09:02.513294.\n",
      "INFO:root:Creating index. Elapsed time since start: 0:09:22.591679.\n",
      "INFO:root:Creating index. Elapsed time since start: 0:09:42.679689.\n",
      "INFO:root:Creating index. Elapsed time since start: 0:10:02.751238.\n",
      "INFO:root:Creating index. Elapsed time since start: 0:10:22.815901.\n",
      "INFO:root:Creating index. Elapsed time since start: 0:10:42.907448.\n",
      "INFO:root:Creating index. Elapsed time since start: 0:11:02.987494.\n",
      "INFO:root:Creating index. Elapsed time since start: 0:11:23.071891.\n",
      "INFO:root:Creating index. Elapsed time since start: 0:11:43.174046.\n",
      "INFO:root:Creating index. Elapsed time since start: 0:12:03.300999.\n",
      "INFO:root:Creating index. Elapsed time since start: 0:12:23.388496.\n",
      "INFO:root:Creating index. Elapsed time since start: 0:12:43.464685.\n",
      "INFO:root:Creating index. Elapsed time since start: 0:13:03.543783.\n",
      "INFO:root:Creating index. Elapsed time since start: 0:13:23.593166.\n",
      "INFO:root:Creating index. Elapsed time since start: 0:13:43.668448.\n",
      "INFO:root:Creating index. Elapsed time since start: 0:14:03.742799.\n",
      "INFO:root:Creating index. Elapsed time since start: 0:14:23.794742.\n",
      "INFO:root:Creating index. Elapsed time since start: 0:14:43.867666.\n",
      "INFO:root:Creating index. Elapsed time since start: 0:15:03.947214.\n",
      "INFO:root:Creating index. Elapsed time since start: 0:15:24.003199.\n",
      "INFO:root:Creating index. Elapsed time since start: 0:15:44.082441.\n",
      "INFO:root:Creating index. Elapsed time since start: 0:16:04.131272.\n",
      "INFO:root:Creating index. Elapsed time since start: 0:16:24.211239.\n",
      "INFO:root:Creating index. Elapsed time since start: 0:16:44.307471.\n",
      "INFO:root:Creating index. Elapsed time since start: 0:17:04.392074.\n",
      "INFO:root:Creating index. Elapsed time since start: 0:17:24.454960.\n",
      "INFO:root:Creating index. Elapsed time since start: 0:17:44.540475.\n",
      "INFO:root:Creating index. Elapsed time since start: 0:18:04.590072.\n",
      "INFO:root:Creating index. Elapsed time since start: 0:18:24.670069.\n",
      "INFO:root:Creating index. Elapsed time since start: 0:18:44.740016.\n",
      "INFO:root:Creating index. Elapsed time since start: 0:19:04.808822.\n",
      "INFO:root:Creating index. Elapsed time since start: 0:19:24.883770.\n",
      "INFO:root:Creating index. Elapsed time since start: 0:19:44.964622.\n",
      "INFO:root:Creating index. Elapsed time since start: 0:20:05.017538.\n",
      "INFO:root:Creating index. Elapsed time since start: 0:20:25.093771.\n",
      "INFO:root:Creating index. Elapsed time since start: 0:20:45.168084.\n",
      "INFO:root:Creating index. Elapsed time since start: 0:21:05.253912.\n",
      "INFO:root:Creating index. Elapsed time since start: 0:21:25.317701.\n",
      "INFO:root:Creating index. Elapsed time since start: 0:21:45.387286.\n",
      "INFO:root:Creating index. Elapsed time since start: 0:22:05.448035.\n",
      "INFO:root:Creating index. Elapsed time since start: 0:22:25.517045.\n",
      "INFO:root:Creating index. Elapsed time since start: 0:22:45.582813.\n",
      "INFO:root:Creating index. Elapsed time since start: 0:23:05.664538.\n",
      "INFO:root:Creating index. Elapsed time since start: 0:23:25.734377.\n",
      "INFO:root:Creating index. Elapsed time since start: 0:23:45.798041.\n",
      "INFO:root:Creating index. Elapsed time since start: 0:24:05.890407.\n",
      "INFO:root:Creating index. Elapsed time since start: 0:24:25.958468.\n",
      "INFO:root:Creating index. Elapsed time since start: 0:24:46.027182.\n",
      "INFO:root:Creating index. Elapsed time since start: 0:25:06.090993.\n",
      "INFO:root:Creating index. Elapsed time since start: 0:25:26.151165.\n",
      "INFO:root:Creating index. Elapsed time since start: 0:25:46.221972.\n",
      "INFO:root:Creating index. Elapsed time since start: 0:26:06.320399.\n",
      "INFO:root:Creating index. Elapsed time since start: 0:26:26.400192.\n",
      "INFO:root:Creating index. Elapsed time since start: 0:26:46.489112.\n",
      "INFO:root:Creating index. Elapsed time since start: 0:27:06.562337.\n",
      "INFO:root:Creating index. Elapsed time since start: 0:27:26.626822.\n",
      "INFO:root:Creating index. Elapsed time since start: 0:27:46.699035.\n",
      "INFO:root:Creating index. Elapsed time since start: 0:28:06.777480.\n",
      "INFO:root:Creating index. Elapsed time since start: 0:28:26.855031.\n",
      "INFO:root:Creating index. Elapsed time since start: 0:28:46.933206.\n",
      "INFO:root:Creating index. Elapsed time since start: 0:29:07.004962.\n",
      "INFO:root:Creating index. Elapsed time since start: 0:29:27.074817.\n",
      "INFO:root:Creating index. Elapsed time since start: 0:29:47.134145.\n",
      "INFO:root:Creating index. Elapsed time since start: 0:30:07.194588.\n",
      "INFO:root:Creating index. Elapsed time since start: 0:30:27.266363.\n",
      "INFO:root:Creating index. Elapsed time since start: 0:30:47.332907.\n",
      "INFO:root:Creating index. Elapsed time since start: 0:31:07.416428.\n",
      "INFO:root:Creating index. Elapsed time since start: 0:31:27.502465.\n",
      "INFO:root:Creating index. Elapsed time since start: 0:31:47.588763.\n",
      "INFO:root:Creating index. Elapsed time since start: 0:32:07.648029.\n",
      "INFO:root:Creating index. Elapsed time since start: 0:32:27.711926.\n",
      "INFO:root:Creating index. Elapsed time since start: 0:32:47.786019.\n",
      "INFO:root:Creating index. Elapsed time since start: 0:33:07.860233.\n",
      "INFO:root:Creating index. Elapsed time since start: 0:33:27.933285.\n",
      "INFO:root:Creating index. Elapsed time since start: 0:33:48.023414.\n",
      "INFO:root:Creating index. Elapsed time since start: 0:34:08.091178.\n",
      "INFO:root:Creating index. Elapsed time since start: 0:34:28.166034.\n",
      "INFO:root:Creating index. Elapsed time since start: 0:34:48.249536.\n",
      "INFO:root:Operation completed!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'@type': 'type.googleapis.com/google.cloud.aiplatform.v1alpha1.Index', 'name': 'projects/733956866731/locations/us-central1/indexes/3018854309593874432'}\n"
     ]
    }
   ],
   "source": [
    "logging.getLogger().setLevel(logging.INFO)\n",
    "\n",
    "operation_id = index_client.create_index(index_display_name, \n",
    "                                          index_description,\n",
    "                                          index_metadata)\n",
    "\n",
    "response = index_client.wait_for_completion(operation_id, 'Creating index', 20)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Verify that the index was created"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "projects/733956866731/locations/us-central1/indexes/3018854309593874432\n",
      "Index: 3018854309593874432 will be used for deployment\n"
     ]
    }
   ],
   "source": [
    "indexes = index_client.list_indexes(index_display_name)\n",
    "\n",
    "for index in indexes:\n",
    "    print(index['name'])\n",
    "\n",
    "if indexes: \n",
    "    index_id = index['name'].split('/')[-1]\n",
    "    print(f'Index: {index_id} will be used for deployment')\n",
    "else:\n",
    "    print('No indexes available for deployment')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the index deployment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### List all endpoints registered with the ANN service"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are not any endpoints registered with the service\n"
     ]
    }
   ],
   "source": [
    "endpoints = deployment_client.list_endpoints()\n",
    "\n",
    "if not endpoints:\n",
    "    print('There are not any endpoints registered with the service')\n",
    "\n",
    "for endpoint in endpoints:\n",
    "    print(endpoint['name'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create an index endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "deployment_display_name = 'Products embeddings endpoint'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Waiting for endpoint. Elapsed time since start: 0:00:00.098077.\n",
      "INFO:root:Operation completed!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'@type': 'type.googleapis.com/google.cloud.aiplatform.v1alpha1.IndexEndpoint', 'name': 'projects/733956866731/locations/us-central1/indexEndpoints/7573400907748999168'}\n"
     ]
    }
   ],
   "source": [
    "operation_id = deployment_client.create_endpoint(deployment_display_name, VPC_NAME)\n",
    "\n",
    "response = index_client.wait_for_completion(operation_id, 'Waiting for endpoint', 10)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Verify that the endpoint was created"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "projects/733956866731/locations/us-central1/indexEndpoints/7573400907748999168\n",
      "Endpoint: 7573400907748999168 will be used for deployment\n"
     ]
    }
   ],
   "source": [
    "endpoints = deployment_client.list_endpoints(deployment_display_name)\n",
    "\n",
    "for endpoint in endpoints:\n",
    "    print(endpoint['name'])\n",
    "    \n",
    "if endpoints: \n",
    "    endpoint_id = endpoint['name'].split('/')[-1]\n",
    "    print(f'Endpoint: {endpoint_id} will be used for deployment')\n",
    "else:\n",
    "    print('No endpoints available for deployment')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Deploy the index to the endpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Set the deployed index ID\n",
    "\n",
    "The ID of the deployed index must be unique within your project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "deployed_index_id = 'product_embeddings_deployed_ind'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Deploy the index\n",
    "\n",
    "Be patient. Index deployment is a long running operation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Operation completed!\n"
     ]
    }
   ],
   "source": [
    "response = index_client.wait_for_completion(operation_id, 'Waiting for deployment', 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Waiting for deployment. Elapsed time since start: 0:00:00.144543.\n",
      "INFO:root:Waiting for deployment. Elapsed time since start: 0:00:10.199308.\n",
      "INFO:root:Waiting for deployment. Elapsed time since start: 0:00:20.267708.\n",
      "INFO:root:Waiting for deployment. Elapsed time since start: 0:00:30.322752.\n",
      "INFO:root:Waiting for deployment. Elapsed time since start: 0:00:40.375460.\n",
      "INFO:root:Waiting for deployment. Elapsed time since start: 0:00:50.422122.\n",
      "INFO:root:Waiting for deployment. Elapsed time since start: 0:01:00.999675.\n",
      "INFO:root:Waiting for deployment. Elapsed time since start: 0:01:11.065783.\n",
      "INFO:root:Waiting for deployment. Elapsed time since start: 0:01:21.131241.\n",
      "INFO:root:Waiting for deployment. Elapsed time since start: 0:01:31.180398.\n",
      "INFO:root:Waiting for deployment. Elapsed time since start: 0:01:41.239141.\n",
      "INFO:root:Waiting for deployment. Elapsed time since start: 0:01:51.287332.\n",
      "INFO:root:Waiting for deployment. Elapsed time since start: 0:02:01.343314.\n",
      "INFO:root:Waiting for deployment. Elapsed time since start: 0:02:11.399301.\n",
      "INFO:root:Waiting for deployment. Elapsed time since start: 0:02:21.447933.\n",
      "INFO:root:Waiting for deployment. Elapsed time since start: 0:02:31.505310.\n",
      "INFO:root:Waiting for deployment. Elapsed time since start: 0:02:41.561456.\n",
      "INFO:root:Waiting for deployment. Elapsed time since start: 0:02:51.603334.\n",
      "INFO:root:Waiting for deployment. Elapsed time since start: 0:03:01.648299.\n",
      "INFO:root:Waiting for deployment. Elapsed time since start: 0:03:11.723583.\n",
      "INFO:root:Waiting for deployment. Elapsed time since start: 0:03:21.787921.\n",
      "INFO:root:Waiting for deployment. Elapsed time since start: 0:03:31.843974.\n",
      "INFO:root:Waiting for deployment. Elapsed time since start: 0:03:41.902484.\n",
      "INFO:root:Waiting for deployment. Elapsed time since start: 0:03:51.979505.\n",
      "INFO:root:Waiting for deployment. Elapsed time since start: 0:04:02.072281.\n",
      "INFO:root:Waiting for deployment. Elapsed time since start: 0:04:12.118846.\n",
      "INFO:root:Waiting for deployment. Elapsed time since start: 0:04:22.183079.\n",
      "INFO:root:Waiting for deployment. Elapsed time since start: 0:04:32.255943.\n",
      "INFO:root:Waiting for deployment. Elapsed time since start: 0:04:42.305284.\n",
      "INFO:root:Waiting for deployment. Elapsed time since start: 0:04:52.367190.\n",
      "INFO:root:Waiting for deployment. Elapsed time since start: 0:05:02.423387.\n",
      "INFO:root:Waiting for deployment. Elapsed time since start: 0:05:12.485990.\n",
      "INFO:root:Waiting for deployment. Elapsed time since start: 0:05:22.608525.\n",
      "INFO:root:Waiting for deployment. Elapsed time since start: 0:05:32.662185.\n",
      "INFO:root:Waiting for deployment. Elapsed time since start: 0:05:42.735775.\n",
      "INFO:root:Waiting for deployment. Elapsed time since start: 0:05:52.792045.\n",
      "INFO:root:Waiting for deployment. Elapsed time since start: 0:06:02.839598.\n",
      "INFO:root:Waiting for deployment. Elapsed time since start: 0:06:12.912666.\n",
      "INFO:root:Waiting for deployment. Elapsed time since start: 0:06:22.972203.\n",
      "INFO:root:Waiting for deployment. Elapsed time since start: 0:06:33.028140.\n",
      "INFO:root:Waiting for deployment. Elapsed time since start: 0:06:43.086600.\n",
      "INFO:root:Waiting for deployment. Elapsed time since start: 0:06:53.159798.\n",
      "INFO:root:Waiting for deployment. Elapsed time since start: 0:07:03.226483.\n",
      "INFO:root:Waiting for deployment. Elapsed time since start: 0:07:13.287952.\n",
      "INFO:root:Waiting for deployment. Elapsed time since start: 0:07:23.364350.\n",
      "INFO:root:Waiting for deployment. Elapsed time since start: 0:07:33.422914.\n",
      "INFO:root:Waiting for deployment. Elapsed time since start: 0:07:43.503258.\n",
      "INFO:root:Waiting for deployment. Elapsed time since start: 0:07:53.555357.\n",
      "INFO:root:Waiting for deployment. Elapsed time since start: 0:08:03.609992.\n",
      "INFO:root:Waiting for deployment. Elapsed time since start: 0:08:13.671718.\n",
      "INFO:root:Waiting for deployment. Elapsed time since start: 0:08:23.733525.\n",
      "INFO:root:Waiting for deployment. Elapsed time since start: 0:08:33.779714.\n",
      "INFO:root:Waiting for deployment. Elapsed time since start: 0:08:43.853131.\n",
      "INFO:root:Waiting for deployment. Elapsed time since start: 0:08:53.901331.\n",
      "INFO:root:Waiting for deployment. Elapsed time since start: 0:09:03.951353.\n",
      "INFO:root:Waiting for deployment. Elapsed time since start: 0:09:14.021616.\n",
      "INFO:root:Waiting for deployment. Elapsed time since start: 0:09:24.070450.\n",
      "INFO:root:Waiting for deployment. Elapsed time since start: 0:09:34.123327.\n",
      "INFO:root:Waiting for deployment. Elapsed time since start: 0:09:44.185206.\n",
      "INFO:root:Waiting for deployment. Elapsed time since start: 0:09:54.264828.\n",
      "INFO:root:Waiting for deployment. Elapsed time since start: 0:10:04.319541.\n",
      "INFO:root:Waiting for deployment. Elapsed time since start: 0:10:14.370540.\n",
      "INFO:root:Waiting for deployment. Elapsed time since start: 0:10:24.442558.\n",
      "INFO:root:Waiting for deployment. Elapsed time since start: 0:10:34.489001.\n",
      "INFO:root:Waiting for deployment. Elapsed time since start: 0:10:44.587630.\n",
      "INFO:root:Waiting for deployment. Elapsed time since start: 0:10:54.630486.\n",
      "INFO:root:Waiting for deployment. Elapsed time since start: 0:11:04.676700.\n",
      "INFO:root:Waiting for deployment. Elapsed time since start: 0:11:14.731956.\n",
      "INFO:root:Waiting for deployment. Elapsed time since start: 0:11:24.856015.\n",
      "INFO:root:Waiting for deployment. Elapsed time since start: 0:11:34.920883.\n",
      "INFO:root:Waiting for deployment. Elapsed time since start: 0:11:45.002247.\n",
      "INFO:root:Waiting for deployment. Elapsed time since start: 0:11:55.065226.\n",
      "INFO:root:Waiting for deployment. Elapsed time since start: 0:12:05.130738.\n",
      "INFO:root:Waiting for deployment. Elapsed time since start: 0:12:15.194231.\n",
      "INFO:root:Waiting for deployment. Elapsed time since start: 0:12:25.249004.\n",
      "INFO:root:Waiting for deployment. Elapsed time since start: 0:12:35.318169.\n",
      "INFO:root:Operation completed!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'name': 'projects/733956866731/locations/us-central1/indexEndpoints/7573400907748999168/operations/7301028512926793728', 'metadata': {'@type': 'type.googleapis.com/google.cloud.aiplatform.v1alpha1.DeployIndexOperationMetadata', 'genericMetadata': {'createTime': '2021-09-20T22:31:55.542198Z', 'updateTime': '2021-09-20T22:44:33.355559Z'}, 'deployedIndexId': 'product_embeddings_deployed_ind'}, 'done': True, 'response': {'@type': 'type.googleapis.com/google.cloud.aiplatform.v1alpha1.DeployIndexResponse', 'deployedIndex': {'id': 'product_embeddings_deployed_ind'}}}\n"
     ]
    }
   ],
   "source": [
    "operation_id = deployment_client.create_deployment(deployment_display_name, \n",
    "                                                   deployed_index_id,\n",
    "                                                   endpoint_id,\n",
    "                                                   index_id)\n",
    "\n",
    "response = index_client.wait_for_completion(operation_id, 'Waiting for deployment', 10)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Querying the ANN service\n",
    "\n",
    "You will use the gRPC interface to query the deployed index."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retrieve the gRPC private endpoint for the ANN Match service"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gRPC endpoint for the: product_embeddings_deployed_ind deployment is: 10.120.0.5:10000\n"
     ]
    }
   ],
   "source": [
    "deployed_index_ip = deployment_client.get_deployment_grpc_ip(endpoint_id, deployed_index_id)\n",
    "endpoint = f'{deployed_index_ip}:{MATCH_SERVICE_PORT}'\n",
    "print(f'gRPC endpoint for the: {deployed_index_id} deployment is: {endpoint}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a helper wrapper around the Match Service gRPC API.\n",
    "\n",
    "The wrapper uses the pre-generated gRPC stub to the Online Querying gRPC interface. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MatchService(object):\n",
    "    \"\"\"This is a wrapper around Online Querying gRPC interface.\"\"\"\n",
    "    def __init__(self, endpoint, deployed_index_id):\n",
    "        self.endpoint = endpoint\n",
    "        self.deployed_index_id = deployed_index_id\n",
    "\n",
    "    def single_match(\n",
    "        self,\n",
    "        embedding: List[float],\n",
    "        num_neighbors: int) -> List[Tuple[str, float]]:\n",
    "        \"\"\"Requests a match for a single embedding.\"\"\"\n",
    "    \n",
    "        match_request = match_pb2.MatchRequest(deployed_index_id=self.deployed_index_id,\n",
    "                                               float_val=embedding,\n",
    "                                               num_neighbors=num_neighbors)\n",
    "        with grpc.insecure_channel(endpoint, options=(('grpc.enable_http_proxy', 0),)) as channel:\n",
    "            stub = match_pb2_grpc.MatchServiceStub(channel)\n",
    "            response = stub.Match(match_request)\n",
    "    \n",
    "        return [(neighbor.id, neighbor.distance) for neighbor in response.neighbor]\n",
    "\n",
    "\n",
    "    def batch_match(\n",
    "        self,\n",
    "        embeddings: List[List[float]],\n",
    "        num_neighbors: int) -> List[List[Tuple[str, float]]]:\n",
    "        \"\"\"Requests matches ofr a list of embeddings.\"\"\"\n",
    "    \n",
    "        match_requests = [\n",
    "            match_pb2.MatchRequest(deployed_index_id=self.deployed_index_id,\n",
    "                                   float_val=embedding,\n",
    "                                   num_neighbors=num_neighbors)\n",
    "            for embedding in embeddings]\n",
    "    \n",
    "        batches_per_index = [\n",
    "            match_pb2.BatchMatchRequest.BatchMatchRequestPerIndex(\n",
    "                deployed_index_id=self.deployed_index_id,\n",
    "                requests=match_requests)]\n",
    "    \n",
    "        batch_match_request = match_pb2.BatchMatchRequest(\n",
    "            requests=batches_per_index)\n",
    "    \n",
    "        with grpc.insecure_channel(endpoint) as channel:\n",
    "            stub = match_pb2_grpc.MatchServiceStub(channel)\n",
    "            response = stub.BatchMatch(batch_match_request)\n",
    "        \n",
    "        matches = []\n",
    "        for batch_per_index in response.responses:\n",
    "            for match in batch_per_index.responses:\n",
    "                matches.append(\n",
    "                    [(neighbor.id, neighbor.distance) for neighbor in match.neighbor])\n",
    "        \n",
    "        return matches\n",
    "    \n",
    "match_service = MatchService(endpoint, deployed_index_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare sample data\n",
    "\n",
    "Retrieve a few embeddings from the BigQuery embedding table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Query complete after 0.00s: 100%|██████████| 1/1 [00:00<00:00, 733.91query/s] \n",
      "Downloading: 100%|██████████| 100/100 [00:01<00:00, 83.61rows/s] \n"
     ]
    }
   ],
   "source": [
    "%%bigquery df_embeddings\n",
    "\n",
    "SELECT item_id, embedding\n",
    "FROM `rec-ai-demo-326116.css_retail.item_embeddings`\n",
    "LIMIT 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-3.806297101245312,\n",
       " -15.78938341682279,\n",
       " 10.878980769866642,\n",
       " 5.760965677607754,\n",
       " -2.7687092376605698,\n",
       " -12.171721530121607,\n",
       " 2.2283898258915977,\n",
       " -5.271758604215919,\n",
       " -24.498092482700436,\n",
       " 4.39482614207085,\n",
       " -2.0724808184591166,\n",
       " 33.44620651536166,\n",
       " -7.893344359345121,\n",
       " 6.551653064580407,\n",
       " -2.1018886213217414,\n",
       " 29.703981647415986,\n",
       " -10.146021658133876,\n",
       " 0.2748278059830755,\n",
       " 11.25628636636933,\n",
       " 23.72181121481588,\n",
       " 19.976807113372054,\n",
       " 9.759315510500064,\n",
       " 3.651946215848869,\n",
       " 8.56964901856156,\n",
       " -18.746348404618665,\n",
       " 2.887023670920412,\n",
       " -10.407702836744022,\n",
       " 2.1968258871235267,\n",
       " -3.363959404070823,\n",
       " 2.5375225633190035,\n",
       " -3.5019245211637315,\n",
       " -3.8072199642980755,\n",
       " -0.9097114055869673,\n",
       " 5.226877233859579,\n",
       " -8.936797602271083,\n",
       " 11.98517325507575,\n",
       " 13.745920006956775,\n",
       " 5.04213765955379,\n",
       " 6.46930988155931,\n",
       " 1.9311396935945007,\n",
       " -4.130503033980623,\n",
       " -14.32082046954076,\n",
       " 4.013387978737336,\n",
       " -20.364025222230776,\n",
       " -5.635485662102075,\n",
       " -1.220635864599934,\n",
       " -0.14946465752155927,\n",
       " 6.127294895340738,\n",
       " 13.628469858256176,\n",
       " -7.643302245202507]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_embeddings = [list(embedding) for embedding in df_embeddings['embedding']]\n",
    "sample_embeddings[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run a single match query\n",
    "\n",
    "The following call requests 10 closest neighbours for a single embedding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.53 ms, sys: 4.41 ms, total: 5.94 ms\n",
      "Wall time: 47.4 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('16112', 1.0),\n",
       " ('28615', 0.864827036857605),\n",
       " ('22736', 0.8534191250801086),\n",
       " ('28363', 0.848035454750061),\n",
       " ('19814', 0.8476966619491577),\n",
       " ('18058', 0.8466648459434509),\n",
       " ('19838', 0.8378995060920715),\n",
       " ('19960', 0.8377876281738281),\n",
       " ('28448', 0.8372305631637573),\n",
       " ('23680', 0.834179162979126)]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time \n",
    "\n",
    "single_match = match_service.single_match(sample_embeddings[50], 10)\n",
    "single_match"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run a batch match query\n",
    "\n",
    "The following call requests 3 closest neighbours for each of the embeddings in a batch of 50."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.76 ms, sys: 3.5 ms, total: 6.25 ms\n",
      "Wall time: 53.5 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[[('16128', 1.0),\n",
       "  ('24554', 0.8871384859085083),\n",
       "  ('21953', 0.8854265213012695)],\n",
       " [('17153', 1.0),\n",
       "  ('18861', 0.8875494003295898),\n",
       "  ('26504', 0.8736223578453064)],\n",
       " [('27422', 1.0),\n",
       "  ('18830', 0.8858315348625183),\n",
       "  ('27431', 0.8765312433242798)],\n",
       " [('13604', 1.0), ('3187', 0.8884710073471069), ('130', 0.8666682243347168)],\n",
       " [('3623', 0.9999998807907104),\n",
       "  ('3480', 0.8563003540039062),\n",
       "  ('26716', 0.8337805271148682)],\n",
       " [('810', 1.0), ('130', 0.8778303265571594), ('13604', 0.8600077033042908)],\n",
       " [('13612', 0.9999998807907104),\n",
       "  ('2438', 0.8249245882034302),\n",
       "  ('13599', 0.7785738706588745)],\n",
       " [('302', 0.9999998807907104),\n",
       "  ('28445', 0.8621522188186646),\n",
       "  ('6429', 0.8611807823181152)],\n",
       " [('1070', 1.0000001192092896),\n",
       "  ('12820', 0.9140549302101135),\n",
       "  ('15272', 0.9125449657440186)],\n",
       " [('12851', 0.9999998807907104),\n",
       "  ('15304', 0.8509014844894409),\n",
       "  ('8872', 0.8405501842498779)],\n",
       " [('7989', 1.0), ('3663', 0.8957894444465637), ('10713', 0.8406054973602295)],\n",
       " [('28471', 1.0), ('28356', 0.888252854347229), ('27478', 0.8722465634346008)],\n",
       " [('7486', 1.0), ('19880', 0.892526388168335), ('22709', 0.8813197612762451)],\n",
       " [('4166', 0.9999999403953552),\n",
       "  ('4140', 0.8710203170776367),\n",
       "  ('130', 0.8404138088226318)],\n",
       " [('9543', 1.0), ('434', 0.8789145946502686), ('8085', 0.8662362694740295)],\n",
       " [('20551', 1.0),\n",
       "  ('18068', 0.9755916595458984),\n",
       "  ('21656', 0.9732340574264526)],\n",
       " [('4169', 0.9999999403953552),\n",
       "  ('21744', 0.8667726516723633),\n",
       "  ('8081', 0.8663347959518433)],\n",
       " [('20559', 0.9999998807907104),\n",
       "  ('20551', 0.8943381309509277),\n",
       "  ('18066', 0.8918575644493103)],\n",
       " [('5715', 1.0), ('329', 0.8828721046447754), ('26547', 0.8773879408836365)],\n",
       " [('3158', 1.0), ('4818', 0.8677343130111694), ('28339', 0.8662828207015991)],\n",
       " [('5726', 1.0), ('13659', 0.8822081685066223), ('5109', 0.8625988364219666)],\n",
       " [('8034', 1.0), ('145', 0.834773063659668), ('5711', 0.8266539573669434)],\n",
       " [('26467', 0.9999999403953552),\n",
       "  ('22733', 0.8527724742889404),\n",
       "  ('23679', 0.8474003076553345)],\n",
       " [('10348', 1.0),\n",
       "  ('13644', 0.8831946849822998),\n",
       "  ('19010', 0.8774253129959106)],\n",
       " [('13684', 1.0), ('173', 0.8855287432670593), ('6446', 0.8820421695709229)],\n",
       " [('10362', 1.0), ('4352', 0.8278733491897583), ('2501', 0.8264747262001038)],\n",
       " [('125', 1.0), ('12714', 0.8336904644966125), ('3352', 0.8194171190261841)],\n",
       " [('22913', 1.0), ('28314', 0.967822790145874), ('23767', 0.8902483582496643)],\n",
       " [('16258', 1.0), ('22752', 0.8945101499557495), ('4609', 0.8895544409751892)],\n",
       " [('18833', 1.0), ('18829', 0.8624267578125), ('26542', 0.8330574035644531)],\n",
       " [('2450', 1.0000001192092896),\n",
       "  ('2457', 0.865127444267273),\n",
       "  ('362', 0.8639249205589294)],\n",
       " [('8850', 1.0), ('7167', 0.878050684928894), ('8915', 0.8462871313095093)],\n",
       " [('404', 1.0), ('7621', 0.8992730975151062), ('156', 0.8987036943435669)],\n",
       " [('19860', 0.9999998807907104),\n",
       "  ('19852', 0.8722677230834961),\n",
       "  ('23015', 0.8635627031326294)],\n",
       " [('24492', 1.0), ('7646', 0.9045376777648926), ('3294', 0.8735071420669556)],\n",
       " [('7607', 1.0), ('3890', 0.8613349199295044), ('8099', 0.8453463912010193)],\n",
       " [('4284', 0.9999998807907104),\n",
       "  ('3405', 0.8520475029945374),\n",
       "  ('7268', 0.8463531136512756)],\n",
       " [('28352', 1.0),\n",
       "  ('10773', 0.8892571330070496),\n",
       "  ('26603', 0.8700293302536011)],\n",
       " [('24521', 1.0), ('24510', 0.8840422630310059), ('16275', 0.85687255859375)],\n",
       " [('2509', 0.9999999403953552),\n",
       "  ('3405', 0.885991632938385),\n",
       "  ('2466', 0.8795230984687805)],\n",
       " [('17358', 1.0), ('17413', 0.9134748578071594), ('4681', 0.8818273544311523)],\n",
       " [('7119', 1.0), ('7116', 0.8716853857040405), ('8860', 0.8581172823905945)],\n",
       " [('5328', 1.0), ('8086', 0.8759979009628296), ('7490', 0.8564648628234863)],\n",
       " [('21712', 0.9999998807907104),\n",
       "  ('17195', 0.8765755295753479),\n",
       "  ('22754', 0.8670201301574707)],\n",
       " [('18132', 1.0),\n",
       "  ('20602', 0.8557187914848328),\n",
       "  ('20583', 0.8496128916740417)],\n",
       " [('19925', 1.0),\n",
       "  ('17270', 0.8545769453048706),\n",
       "  ('21752', 0.8528208136558533)],\n",
       " [('18134', 0.9999998807907104),\n",
       "  ('17113', 0.9086690545082092),\n",
       "  ('394', 0.900262176990509)],\n",
       " [('16347', 1.0),\n",
       "  ('18027', 0.8945720195770264),\n",
       "  ('21770', 0.8637936115264893)],\n",
       " [('7645', 1.0), ('20453', 0.9052674174308777), ('3732', 0.9011290669441223)],\n",
       " [('8160', 1.0), ('6467', 0.8691094517707825), ('3227', 0.8634070754051208)]]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time \n",
    "\n",
    "batch_match = match_service.batch_match(sample_embeddings[0:50], 3)\n",
    "batch_match"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean up\n",
    "\n",
    "**WARNING**\n",
    "\n",
    "The below code will delete all ANN deployments, endpoints, and indexes in the configured project.\n",
    "\n",
    "### Delete index deployments and endpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deleting endpoint: projects/895222332033/locations/us-central1/indexEndpoints/856246879153815552\n",
      "Deleting endpoint: projects/895222332033/locations/us-central1/indexEndpoints/3621457050359300096\n",
      "Deleting endpoint: projects/895222332033/locations/us-central1/indexEndpoints/108649341010313216\n"
     ]
    }
   ],
   "source": [
    "for endpoint in deployment_client.list_endpoints():\n",
    "    endpoint_id = endpoint['name'].split('/')[-1]\n",
    "    if 'deployedIndexes' in endpoint.keys():\n",
    "        for deployment in endpoint['deployedIndexes']:\n",
    "            print('   Deleting index deployment: {} in the endpoint: {} '.format(deployment['id'], endpoint_id))\n",
    "            deployment_client.delete_deployment(endpoint_id, deployment['id'])\n",
    "    print('Deleting endpoint: {}'.format(endpoint['name']))\n",
    "    deployment_client.delete_endpoint(endpoint_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Delete indexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deleting index: projects/895222332033/locations/us-central1/indexes/1335880239468773376\n",
      "Deleting index: projects/895222332033/locations/us-central1/indexes/3544895856694001664\n",
      "Deleting index: projects/895222332033/locations/us-central1/indexes/4886968545650409472\n"
     ]
    }
   ],
   "source": [
    "for index in index_client.list_indexes():\n",
    "    index_id = index['name'].split('/')[-1]\n",
    "    print('Deleting index: {}'.format(index['name']))\n",
    "    index_client.delete_index(index_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## License\n",
    "\n",
    "Copyright 2020 Google LLC\n",
    "\n",
    "Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "you may not use this file except in compliance with the License. You may obtain a copy of the License at: http://www.apache.org/licenses/LICENSE-2.0\n",
    "\n",
    "Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. \n",
    "\n",
    "See the License for the specific language governing permissions and limitations under the License.\n",
    "\n",
    "**This is not an official Google product but sample code provided for an educational purpose**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "name": "tf2-gpu.2-6.m79",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-6:m79"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
