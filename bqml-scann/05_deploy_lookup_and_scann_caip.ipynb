{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "59DnLe66_RSq"
   },
   "source": [
    "# Part 5: Deploy the solution to AI Platform Prediction\n",
    "\n",
    "This notebook is the fifth of five notebooks that guide you through running the [Real-time Item-to-item Recommendation with BigQuery ML Matrix Factorization and ScaNN](https://github.com/GoogleCloudPlatform/analytics-componentized-patterns/tree/master/retail/recommendation-system/bqml-scann) solution.\n",
    "\n",
    "Use this notebook to complete the following tasks:\n",
    "\n",
    "1. Deploy the embedding lookup model to AI Platform Prediction. \n",
    "2. Deploy the ScaNN matching service to AI Platform Prediction by using a custom container. The ScaNN matching service is an application that wraps the ANN index model and provides additional functionality, like mapping item IDs to item embeddings.\n",
    "3. Optionally, export and deploy the matrix factorization model to AI Platform for exact matching.\n",
    "\n",
    "Before starting this notebook, you must run the [04_build_embeddings_scann](04_build_embeddings_scann.ipynb) notebook to build an approximate nearest neighbor (ANN) index for the item embeddings.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "--twfVSH_RSx"
   },
   "source": [
    "## Setup\r\n",
    "\r\n",
    "Import the required libraries, configure the environment variables, and authenticate your GCP account."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hTf9yuUI_RSy"
   },
   "source": [
    "### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "-74hbUcn_RSy"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "G0-pepnt_RSz"
   },
   "source": [
    "### Configure GCP environment settings\r\n",
    "\r\n",
    "Update the following variables to reflect the values for your GCP environment:\r\n",
    "\r\n",
    "+ `PROJECT_ID`: The ID of the Google Cloud project you are using to implement this solution.\r\n",
    "+ `PROJECT_NUMBER`: The number of the Google Cloud project you are using to implement this solution. You can find this in the **Project info** card on the [project dashboard page](https://pantheon.corp.google.com/home/dashboard).\r\n",
    "+ `BUCKET`: The name of the Cloud Storage bucket you created to use with this solution. The `BUCKET` value should be just the bucket name, so `myBucket` rather than `gs://myBucket`.\r\n",
    "+ `REGION`: The region to use for the AI Platform Prediction job."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "7JijghSw_RSz"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated property [core/project].\n"
     ]
    }
   ],
   "source": [
    "PROJECT_ID = 'rec-ai-demo-326116' # Change to your project.\n",
    "BUCKET = 'rec_bq_jsw' # Change to the bucket you created.\n",
    "REGION = 'us-central1' # Change to your AI Platform Training region.\n",
    "PROJECT_NUMBER = 733956866731\n",
    "ARTIFACTS_REPOSITORY_NAME = 'ml-serving'\n",
    "\n",
    "EMBEDDNIG_LOOKUP_MODEL_OUTPUT_DIR = f'gs://{BUCKET}/bqml/embedding_lookup_model'\n",
    "EMBEDDNIG_LOOKUP_MODEL_NAME = 'item_embedding_lookup'\n",
    "EMBEDDNIG_LOOKUP_MODEL_VERSION = 'v1'\n",
    "\n",
    "INDEX_DIR = f'gs://{BUCKET}/bqml/scann_index'\n",
    "SCANN_MODEL_NAME = 'index_server'\n",
    "SCANN_MODEL_VERSION = 'v1'\n",
    "\n",
    "KIND = 'product'\n",
    "\n",
    "!gcloud config set project $PROJECT_ID"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sRgHeeDH_RS0"
   },
   "source": [
    "### Authenticate your GCP account\n",
    "This is required if you run the notebook in Colab. If you use an AI Platform notebook, you should already be authenticated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "mCRUZhqy_RS1"
   },
   "outputs": [],
   "source": [
    "try:\n",
    "  from google.colab import auth\n",
    "  auth.authenticate_user()\n",
    "  print(\"Colab user is authenticated.\")\n",
    "except: pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dTdkkpNL_RS1"
   },
   "source": [
    "## Deploy the embedding lookup model to AI Platform Prediction\r\n",
    "\r\n",
    "Create the embedding lookup model resource in AI Platform:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.cloud import aiplatform as vertex_ai\n",
    "\n",
    "# initialize vertex sdk\n",
    "vertex_ai.init(\n",
    "    project=PROJECT_ID,\n",
    "    location=REGION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "e_4hhSxr_RS2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using endpoint [https://us-central1-ml.googleapis.com/]\n",
      "Created ai platform model [projects/rec-ai-demo-326116/models/item_embedding_lookup].\n"
     ]
    }
   ],
   "source": [
    "!gcloud ai-platform models create {EMBEDDNIG_LOOKUP_MODEL_NAME} --region={REGION}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nOLmODpvPSvk"
   },
   "source": [
    "Next, deploy the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "o8QANnrC_RS2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using endpoint [https://us-central1-ml.googleapis.com/]\n",
      "Creating version (this might take a few minutes)......done.                    \n",
      "The model version is deployed to AI Platform Prediction.\n"
     ]
    }
   ],
   "source": [
    "!gcloud ai-platform versions create {EMBEDDNIG_LOOKUP_MODEL_VERSION} \\\n",
    "  --region={REGION} \\\n",
    "  --model={EMBEDDNIG_LOOKUP_MODEL_NAME} \\\n",
    "  --origin={EMBEDDNIG_LOOKUP_MODEL_OUTPUT_DIR} \\\n",
    "  --runtime-version=2.2 \\\n",
    "  --framework=TensorFlow \\\n",
    "  --python-version=3.7 \\\n",
    "  --machine-type=n1-standard-2\n",
    "\n",
    "print(\"The model version is deployed to AI Platform Prediction.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "p9Y0KD-CPXw1"
   },
   "source": [
    "Once the model is deployed, you can verify it in the [AI Platform console](https://pantheon.corp.google.com/ai-platform/models)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6gwpUx9q_RS3"
   },
   "source": [
    "### Test the deployed embedding lookup AI Platform Prediction model\r\n",
    "\r\n",
    "Set the AI Platform Prediction API information:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "6a_V-ueo_RS3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:googleapiclient.discovery_cache:file_cache is unavailable when using oauth2client >= 4.0.0 or google-auth\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jupyter/.local/lib/python3.7/site-packages/googleapiclient/discovery_cache/file_cache.py\", line 33, in <module>\n",
      "    from oauth2client.contrib.locked_file import LockedFile\n",
      "ModuleNotFoundError: No module named 'oauth2client.contrib.locked_file'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jupyter/.local/lib/python3.7/site-packages/googleapiclient/discovery_cache/file_cache.py\", line 37, in <module>\n",
      "    from oauth2client.locked_file import LockedFile\n",
      "ModuleNotFoundError: No module named 'oauth2client.locked_file'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jupyter/.local/lib/python3.7/site-packages/googleapiclient/discovery_cache/__init__.py\", line 44, in autodetect\n",
      "    from . import file_cache\n",
      "  File \"/home/jupyter/.local/lib/python3.7/site-packages/googleapiclient/discovery_cache/file_cache.py\", line 41, in <module>\n",
      "    \"file_cache is unavailable when using oauth2client >= 4.0.0 or google-auth\"\n",
      "ImportError: file_cache is unavailable when using oauth2client >= 4.0.0 or google-auth\n"
     ]
    }
   ],
   "source": [
    "import googleapiclient.discovery\n",
    "from google.api_core.client_options import ClientOptions\n",
    "\n",
    "api_endpoint = f'https://{REGION}-ml.googleapis.com'\n",
    "client_options = ClientOptions(api_endpoint=api_endpoint)\n",
    "service = googleapiclient.discovery.build(\n",
    "    serviceName='ml', version='v1', client_options=client_options)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FTucyodISTFi"
   },
   "source": [
    "Run the `caip_embedding_lookup` method to retrieve item embeddings. This method accepts item IDs, calls the embedding lookup model in AI Platform Prediction, and returns the appropriate embedding vectors.\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "y0PYGzvV_RS4"
   },
   "outputs": [],
   "source": [
    "def caip_embedding_lookup(input_items):\n",
    "  request_body = {'instances': input_items}\n",
    "  service_name = f'projects/{PROJECT_ID}/models/{EMBEDDNIG_LOOKUP_MODEL_NAME}/versions/{EMBEDDNIG_LOOKUP_MODEL_VERSION}'\n",
    "  print(f'Calling : {service_name}')\n",
    "  response = service.projects().predict(\n",
    "    name=service_name, body=request_body).execute()\n",
    "\n",
    "  if 'error' in response:\n",
    "    raise RuntimeError(response['error'])\n",
    "\n",
    "  return response['predictions']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NBNQXyIkEz-q"
   },
   "source": [
    "Test the `caip_embedding_lookup` method with three item IDs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "180KDniX_RS4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calling : projects/rec-ai-demo-326116/models/item_embedding_lookup/versions/v1\n",
      "Embeddings retrieved: 3\n",
      "4096: [-1.7246695319570633, -20.72278509212223, 2.3831895504686433, 5.3884580428380495, -7.545703156368214]\n",
      "5120: [-16.081237542875364, -17.31135492643335, -13.651084423117256, 15.45910536252875, -22.220358051221897]\n",
      "4352: [-5.772327741628762, -20.389276482798223, 20.0998311807402, 7.614269508630338, 0.7644814852459331]\n"
     ]
    }
   ],
   "source": [
    "input_items = ['4096', '5120', '4352']\n",
    "\n",
    "embeddings = caip_embedding_lookup(input_items)\n",
    "print(f'Embeddings retrieved: {len(embeddings)}')\n",
    "for idx, embedding in enumerate(embeddings):\n",
    "  print(f'{input_items[idx]}: {embedding[:5]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kZD4MK5k-VGD"
   },
   "source": [
    "## ScaNN matching service\r\n",
    "\r\n",
    "The ScaNN matching service performs the following steps:\r\n",
    "\r\n",
    "1. Receives one or more item IDs from the client.\r\n",
    "1. Calls the embedding lookup model to fetch the embedding vectors of those item IDs.\r\n",
    "1. Uses these embedding vectors to query the ANN index to find approximate nearest neighbor embedding vectors.\r\n",
    "1. Maps the approximate nearest neighbors embedding vectors to their corresponding item IDs.\r\n",
    "1. Sends the item IDs back to the client.\r\n",
    "\r\n",
    "When the client receives the item IDs of the matches, the song title and artist information is fetched from Datastore in real-time to be displayed and served to the client application.\r\n",
    "\r\n",
    "Note: In practice, recommendation systems combine matches (from one or more indices) with user-provided filtering clauses (like where price <= *value* and colour =red), as well as other item metadata (like item categories, popularity, and recency) to ensure recommendation freshness and diversity. In addition, ranking is commonly applied after generating the matches to decide the order in which they are served to the user. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "P0L5qYS1hpl3"
   },
   "source": [
    "### ScaNN matching service implementation\r\n",
    "\r\n",
    "The ScaNN matching service is implemented as a [Flask](https://flask.palletsprojects.com/en/1.1.x/quickstart/) application that runs on a [gunicorn](https://gunicorn.org/) web server. This application is implemented in the [main.py](index_server/main.py) module.\r\n",
    "\r\n",
    "The ScaNN matching service application works as follows:\r\n",
    "\r\n",
    "1. Uses environmental variables to set configuration information, such as the Google Cloud location of the ScaNN index to load.\r\n",
    "1. Loads the ScaNN index as the `ScaNNMatcher` object is initiated.\r\n",
    "1. As [required by AI Platform Prediction](https://cloud.google.com/ai-platform/prediction/docs/custom-container-requirements), exposes two HTTP endpoints:\r\n",
    "    \r\n",
    "    + `health`: a `GET` method to which AI Platform Prediction sends health checks.\r\n",
    "    + `predict`: a `POST` method to which AI Platform Prediction forwards prediction requests.\r\n",
    "\r\n",
    "    The `predict` method expects JSON requests in the form `{\"instances\":[{\"query\": \"item123\", \"show\": 10}]}`, where `query` represents the item ID to retrieve matches for, and `show` represents the number of matches to retrieve.\r\n",
    "    \r\n",
    "    The `predict` method works as follows:\r\n",
    "\r\n",
    "        1. Validates the received request object.\r\n",
    "        1. Extracts the `query` and `show` values from the request object.\r\n",
    "        1. Calls `embedding_lookup.lookup` with the given query item ID to get its embedding vector from the embedding lookup model.\r\n",
    "        1. Calls `scann_matcher.match` with the query item embedding vector to retrieve its approximate nearest neighbor item IDs from the ANN Index.\r\n",
    "The list of matching item IDs are put into JSON format and returned as the response of the `predict` method."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eaeXo9prFNpL"
   },
   "source": [
    "## Deploy the ScaNN matching service to AI Platform Prediction\r\n",
    "\r\n",
    "Package the ScaNN matching service application in a custom container and deploy it to AI Platform Prediction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qkpwIGnb_RS5"
   },
   "source": [
    "### Create an Artifact Registry for the Docker container image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "!gcloud services enable artifactregistry.googleapis.com"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "ru4oMDt2_RS5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create request issued for: [ml-serving]\n",
      "Waiting for operation [projects/rec-ai-demo-326116/locations/us-central1/operat\n",
      "ions/9df10b5a-a066-485d-8814-bcc44890a8e1] to complete...done.                 \n",
      "Created repository [ml-serving].\n"
     ]
    }
   ],
   "source": [
    "!gcloud beta artifacts repositories create {ARTIFACTS_REPOSITORY_NAME} \\\n",
    "  --location={REGION} \\\n",
    "  --repository-format=docker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "fIhDsllM_RS6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;33mWARNING:\u001b[0m Your config file at [/home/jupyter/.docker/config.json] contains these credential helper entries:\n",
      "\n",
      "{\n",
      "  \"credHelpers\": {\n",
      "    \"gcr.io\": \"gcloud\",\n",
      "    \"us.gcr.io\": \"gcloud\",\n",
      "    \"eu.gcr.io\": \"gcloud\",\n",
      "    \"asia.gcr.io\": \"gcloud\",\n",
      "    \"staging-k8s.gcr.io\": \"gcloud\",\n",
      "    \"marketplace.gcr.io\": \"gcloud\"\n",
      "  }\n",
      "}\n",
      "Adding credentials for: us-central1-docker.pkg.dev\n",
      "Docker configuration file updated.\n"
     ]
    }
   ],
   "source": [
    "!gcloud beta auth configure-docker {REGION}-docker.pkg.dev --quiet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eTG7nvvt_RS6"
   },
   "source": [
    "### Use Cloud Build to build the Docker container image\n",
    "\n",
    "The container runs the gunicorn HTTP web server and executes the Flask [app](https://github.com/GoogleCloudPlatform/analytics-componentized-patterns/blob/315040032df26d7cef3a26e5def35ca50dd559d6/retail/recommendation-system/bqml-scann/index_server/main.py#L35) variable defined in the `main.py` module.\n",
    "\n",
    "The container image to deploy to AI Platform Prediction is defined in a [Dockerfile](index_server/Dockerfile), as shown in the following code snippet:\n",
    "\n",
    "```\n",
    "FROM python:3.8-slim\n",
    "\n",
    "COPY requirements.txt .\n",
    "RUN pip install -r requirements.txt\n",
    "\n",
    "COPY . ./\n",
    "\n",
    "ARG PORT\n",
    "ENV PORT=$PORT\n",
    "\n",
    "CMD exec gunicorn --bind :$PORT main:app  --workers=1 --threads 8 --timeout 1800\n",
    "```\n",
    "\n",
    "Build the container image by using Cloud Build and specifying the [cloudbuild.yaml](index_server/cloudbuild.yaml) file:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing index_server/cloudbuild.yaml\n"
     ]
    }
   ],
   "source": [
    "%%writefile index_server/cloudbuild.yaml\n",
    "steps:\n",
    "\n",
    "- name: 'gcr.io/cloud-builders/docker'\n",
    "  args: ['build', '--tag', '${_IMAGE_URL}', '.', '--build-arg=PORT=${_PORT}']\n",
    "  dir: 'index_server'\n",
    "\n",
    "images: ['${_IMAGE_URL}']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "QVopE8-0_RS6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating temporary tarball archive of 58 file(s) totalling 2.5 MiB before compression.\n",
      "Some files were not included in the source upload.\n",
      "\n",
      "Check the gcloud log [/home/jupyter/.config/gcloud/logs/2021.09.20/20.03.48.220330.log] to see which files and the contents of the\n",
      "default gcloudignore file used (see `$ gcloud topic gcloudignore` to learn\n",
      "more).\n",
      "\n",
      "Uploading tarball of [.] to [gs://rec-ai-demo-326116_cloudbuild/source/1632168228.314874-16089a2f9d5547e7927d519977f69a7f.tgz]\n",
      "Created [https://cloudbuild.googleapis.com/v1/projects/rec-ai-demo-326116/locations/global/builds/bbd1b28e-48a8-4b3b-94e9-318a9827efec].\n",
      "Logs are available at [https://console.cloud.google.com/cloud-build/builds/bbd1b28e-48a8-4b3b-94e9-318a9827efec?project=733956866731].\n",
      "----------------------------- REMOTE BUILD OUTPUT ------------------------------\n",
      "starting build \"bbd1b28e-48a8-4b3b-94e9-318a9827efec\"\n",
      "\n",
      "FETCHSOURCE\n",
      "Fetching storage object: gs://rec-ai-demo-326116_cloudbuild/source/1632168228.314874-16089a2f9d5547e7927d519977f69a7f.tgz#1632168229833786\n",
      "Copying gs://rec-ai-demo-326116_cloudbuild/source/1632168228.314874-16089a2f9d5547e7927d519977f69a7f.tgz#1632168229833786...\n",
      "/ [1 files][  1.7 MiB/  1.7 MiB]                                                \n",
      "Operation completed over 1 objects/1.7 MiB.\n",
      "BUILD\n",
      "Already have image (with digest): gcr.io/cloud-builders/docker\n",
      "Sending build context to Docker daemon  11.78kB\n",
      "Step 1/7 : FROM python:3.8-slim\n",
      "3.8-slim: Pulling from library/python\n",
      "f8416d8bac72: Pulling fs layer\n",
      "3d1fe1074eae: Pulling fs layer\n",
      "01ee43ff2a96: Pulling fs layer\n",
      "83c2515dd8ac: Pulling fs layer\n",
      "84e681791894: Pulling fs layer\n",
      "83c2515dd8ac: Waiting\n",
      "84e681791894: Waiting\n",
      "3d1fe1074eae: Verifying Checksum\n",
      "3d1fe1074eae: Download complete\n",
      "83c2515dd8ac: Verifying Checksum\n",
      "83c2515dd8ac: Download complete\n",
      "84e681791894: Verifying Checksum\n",
      "84e681791894: Download complete\n",
      "01ee43ff2a96: Verifying Checksum\n",
      "01ee43ff2a96: Download complete\n",
      "f8416d8bac72: Verifying Checksum\n",
      "f8416d8bac72: Download complete\n",
      "f8416d8bac72: Pull complete\n",
      "3d1fe1074eae: Pull complete\n",
      "01ee43ff2a96: Pull complete\n",
      "83c2515dd8ac: Pull complete\n",
      "84e681791894: Pull complete\n",
      "Digest: sha256:4dd66d1ccaddaa0587851cb92b365bf3090dccb41393c6f8bbee5dbefcc085c9\n",
      "Status: Downloaded newer image for python:3.8-slim\n",
      " ---> 0b4039cc52c9\n",
      "Step 2/7 : COPY requirements.txt .\n",
      " ---> 83e889bed12b\n",
      "Step 3/7 : RUN pip install -r requirements.txt\n",
      " ---> Running in 0e9f17f4f539\n",
      "Collecting pip==20.2.4\n",
      "  Downloading pip-20.2.4-py2.py3-none-any.whl (1.5 MB)\n",
      "Collecting Flask==1.1.2\n",
      "  Downloading Flask-1.1.2-py2.py3-none-any.whl (94 kB)\n",
      "Collecting gunicorn==20.0.4\n",
      "  Downloading gunicorn-20.0.4-py2.py3-none-any.whl (77 kB)\n",
      "Collecting google-api-python-client==1.12.5\n",
      "  Downloading google_api_python_client-1.12.5-py2.py3-none-any.whl (61 kB)\n",
      "Collecting scann==1.1.1\n",
      "  Downloading scann-1.1.1-cp38-cp38-manylinux2014_x86_64.whl (11.7 MB)\n",
      "Collecting Werkzeug>=0.15\n",
      "  Downloading Werkzeug-2.0.1-py3-none-any.whl (288 kB)\n",
      "Collecting Jinja2>=2.10.1\n",
      "  Downloading Jinja2-3.0.1-py3-none-any.whl (133 kB)\n",
      "Collecting click>=5.1\n",
      "  Downloading click-8.0.1-py3-none-any.whl (97 kB)\n",
      "Collecting itsdangerous>=0.24\n",
      "  Downloading itsdangerous-2.0.1-py3-none-any.whl (18 kB)\n",
      "Requirement already satisfied: setuptools>=3.0 in /usr/local/lib/python3.8/site-packages (from gunicorn==20.0.4->-r requirements.txt (line 3)) (57.5.0)\n",
      "Collecting google-auth-httplib2>=0.0.3\n",
      "  Downloading google_auth_httplib2-0.1.0-py2.py3-none-any.whl (9.3 kB)\n",
      "Collecting httplib2<1dev,>=0.15.0\n",
      "  Downloading httplib2-0.19.1-py3-none-any.whl (95 kB)\n",
      "Collecting google-auth>=1.16.0\n",
      "  Downloading google_auth-2.1.0-py2.py3-none-any.whl (153 kB)\n",
      "Collecting uritemplate<4dev,>=3.0.0\n",
      "  Downloading uritemplate-3.0.1-py2.py3-none-any.whl (15 kB)\n",
      "Collecting google-api-core<2dev,>=1.21.0\n",
      "  Downloading google_api_core-1.31.3-py2.py3-none-any.whl (93 kB)\n",
      "Collecting six<2dev,>=1.13.0\n",
      "  Downloading six-1.16.0-py2.py3-none-any.whl (11 kB)\n",
      "Collecting numpy\n",
      "  Downloading numpy-1.21.2-cp38-cp38-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (15.8 MB)\n",
      "Collecting tensorflow~=2.3.0\n",
      "  Downloading tensorflow-2.3.4-cp38-cp38-manylinux2010_x86_64.whl (320.7 MB)\n",
      "Collecting requests<3.0.0dev,>=2.18.0\n",
      "  Downloading requests-2.26.0-py2.py3-none-any.whl (62 kB)\n",
      "Collecting packaging>=14.3\n",
      "  Downloading packaging-21.0-py3-none-any.whl (40 kB)\n",
      "Collecting googleapis-common-protos<2.0dev,>=1.6.0\n",
      "  Downloading googleapis_common_protos-1.53.0-py2.py3-none-any.whl (198 kB)\n",
      "Collecting google-auth>=1.16.0\n",
      "  Downloading google_auth-1.35.0-py2.py3-none-any.whl (152 kB)\n",
      "Collecting protobuf<3.18.0,>=3.12.0\n",
      "  Downloading protobuf-3.17.3-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.whl (1.0 MB)\n",
      "Collecting pytz\n",
      "  Downloading pytz-2021.1-py2.py3-none-any.whl (510 kB)\n",
      "Collecting cachetools<5.0,>=2.0.0\n",
      "  Downloading cachetools-4.2.2-py3-none-any.whl (11 kB)\n",
      "Collecting pyasn1-modules>=0.2.1\n",
      "  Downloading pyasn1_modules-0.2.8-py2.py3-none-any.whl (155 kB)\n",
      "Collecting rsa<5,>=3.1.4\n",
      "  Downloading rsa-4.7.2-py3-none-any.whl (34 kB)\n",
      "Collecting pyparsing<3,>=2.4.2\n",
      "  Downloading pyparsing-2.4.7-py2.py3-none-any.whl (67 kB)\n",
      "Collecting MarkupSafe>=2.0\n",
      "  Downloading MarkupSafe-2.0.1-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (30 kB)\n",
      "Collecting pyasn1<0.5.0,>=0.4.6\n",
      "  Downloading pyasn1-0.4.8-py2.py3-none-any.whl (77 kB)\n",
      "Collecting certifi>=2017.4.17\n",
      "  Downloading certifi-2021.5.30-py2.py3-none-any.whl (145 kB)\n",
      "Collecting urllib3<1.27,>=1.21.1\n",
      "  Downloading urllib3-1.26.6-py2.py3-none-any.whl (138 kB)\n",
      "Collecting charset-normalizer~=2.0.0\n",
      "  Downloading charset_normalizer-2.0.6-py3-none-any.whl (37 kB)\n",
      "Collecting idna<4,>=2.5\n",
      "  Downloading idna-3.2-py3-none-any.whl (59 kB)\n",
      "Collecting tensorflow-estimator<2.4.0,>=2.3.0\n",
      "  Downloading tensorflow_estimator-2.3.0-py2.py3-none-any.whl (459 kB)\n",
      "Collecting astunparse==1.6.3\n",
      "  Downloading astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Collecting opt-einsum>=2.3.2\n",
      "  Downloading opt_einsum-3.3.0-py3-none-any.whl (65 kB)\n",
      "Collecting gast==0.3.3\n",
      "  Downloading gast-0.3.3-py2.py3-none-any.whl (9.7 kB)\n",
      "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.8/site-packages (from tensorflow~=2.3.0->scann==1.1.1->-r requirements.txt (line 5)) (0.37.0)\n",
      "Collecting numpy\n",
      "  Downloading numpy-1.18.5-cp38-cp38-manylinux1_x86_64.whl (20.6 MB)\n",
      "Collecting tensorboard<3,>=2.3.0\n",
      "  Downloading tensorboard-2.6.0-py3-none-any.whl (5.6 MB)\n",
      "Collecting h5py<2.11.0,>=2.10.0\n",
      "  Downloading h5py-2.10.0-cp38-cp38-manylinux1_x86_64.whl (2.9 MB)\n",
      "Collecting keras-preprocessing<1.2,>=1.1.1\n",
      "  Downloading Keras_Preprocessing-1.1.2-py2.py3-none-any.whl (42 kB)\n",
      "Collecting grpcio>=1.8.6\n",
      "  Downloading grpcio-1.40.0-cp38-cp38-manylinux2014_x86_64.whl (4.3 MB)\n",
      "Collecting wrapt>=1.11.1\n",
      "  Downloading wrapt-1.12.1.tar.gz (27 kB)\n",
      "Collecting termcolor>=1.1.0\n",
      "  Downloading termcolor-1.1.0.tar.gz (3.9 kB)\n",
      "Collecting absl-py>=0.7.0\n",
      "  Downloading absl_py-0.13.0-py3-none-any.whl (132 kB)\n",
      "Collecting google-pasta>=0.1.8\n",
      "  Downloading google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "Collecting google-auth-oauthlib<0.5,>=0.4.1\n",
      "  Downloading google_auth_oauthlib-0.4.6-py2.py3-none-any.whl (18 kB)\n",
      "Collecting tensorboard-plugin-wit>=1.6.0\n",
      "  Downloading tensorboard_plugin_wit-1.8.0-py3-none-any.whl (781 kB)\n",
      "Collecting markdown>=2.6.8\n",
      "  Downloading Markdown-3.3.4-py3-none-any.whl (97 kB)\n",
      "Collecting tensorboard-data-server<0.7.0,>=0.6.0\n",
      "  Downloading tensorboard_data_server-0.6.1-py3-none-manylinux2010_x86_64.whl (4.9 MB)\n",
      "Collecting requests-oauthlib>=0.7.0\n",
      "  Downloading requests_oauthlib-1.3.0-py2.py3-none-any.whl (23 kB)\n",
      "Collecting oauthlib>=3.0.0\n",
      "  Downloading oauthlib-3.1.1-py2.py3-none-any.whl (146 kB)\n",
      "Building wheels for collected packages: termcolor, wrapt\n",
      "  Building wheel for termcolor (setup.py): started\n",
      "  Building wheel for termcolor (setup.py): finished with status 'done'\n",
      "  Created wheel for termcolor: filename=termcolor-1.1.0-py3-none-any.whl size=4847 sha256=1f57359bbe3d7491057979f97173bff18a79b1a26313ac33b77d9f0cada341a3\n",
      "  Stored in directory: /root/.cache/pip/wheels/a0/16/9c/5473df82468f958445479c59e784896fa24f4a5fc024b0f501\n",
      "  Building wheel for wrapt (setup.py): started\n",
      "  Building wheel for wrapt (setup.py): finished with status 'done'\n",
      "  Created wheel for wrapt: filename=wrapt-1.12.1-py3-none-any.whl size=19572 sha256=ceded1f3b5723ab35d48d9dc4ea051e50bf30e560957d6680a2d7a820e9063c7\n",
      "  Stored in directory: /root/.cache/pip/wheels/5f/fd/9e/b6cf5890494cb8ef0b5eaff72e5d55a70fb56316007d6dfe73\n",
      "Successfully built termcolor wrapt\n",
      "Installing collected packages: urllib3, pyasn1, idna, charset-normalizer, certifi, six, rsa, requests, pyasn1-modules, oauthlib, cachetools, requests-oauthlib, google-auth, Werkzeug, tensorboard-plugin-wit, tensorboard-data-server, pyparsing, protobuf, numpy, markdown, grpcio, google-auth-oauthlib, absl-py, wrapt, termcolor, tensorflow-estimator, tensorboard, pytz, packaging, opt-einsum, MarkupSafe, keras-preprocessing, httplib2, h5py, googleapis-common-protos, google-pasta, gast, astunparse, uritemplate, tensorflow, Jinja2, itsdangerous, google-auth-httplib2, google-api-core, click, scann, pip, gunicorn, google-api-python-client, Flask\n",
      "  Attempting uninstall: pip\n",
      "    Found existing installation: pip 21.2.4\n",
      "    Uninstalling pip-21.2.4:\n",
      "      Successfully uninstalled pip-21.2.4\n",
      "Successfully installed Flask-1.1.2 Jinja2-3.0.1 MarkupSafe-2.0.1 Werkzeug-2.0.1 absl-py-0.13.0 astunparse-1.6.3 cachetools-4.2.2 certifi-2021.5.30 charset-normalizer-2.0.6 click-8.0.1 gast-0.3.3 google-api-core-1.31.3 google-api-python-client-1.12.5 google-auth-1.35.0 google-auth-httplib2-0.1.0 google-auth-oauthlib-0.4.6 google-pasta-0.2.0 googleapis-common-protos-1.53.0 grpcio-1.40.0 gunicorn-20.0.4 h5py-2.10.0 httplib2-0.19.1 idna-3.2 itsdangerous-2.0.1 keras-preprocessing-1.1.2 markdown-3.3.4 numpy-1.18.5 oauthlib-3.1.1 opt-einsum-3.3.0 packaging-21.0 pip-20.2.4 protobuf-3.17.3 pyasn1-0.4.8 pyasn1-modules-0.2.8 pyparsing-2.4.7 pytz-2021.1 requests-2.26.0 requests-oauthlib-1.3.0 rsa-4.7.2 scann-1.1.1 six-1.16.0 tensorboard-2.6.0 tensorboard-data-server-0.6.1 tensorboard-plugin-wit-1.8.0 tensorflow-2.3.4 tensorflow-estimator-2.3.0 termcolor-1.1.0 uritemplate-3.0.1 urllib3-1.26.6 wrapt-1.12.1\n",
      "\u001b[91mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\n",
      "\u001b[0mRemoving intermediate container 0e9f17f4f539\n",
      " ---> 67bf912ef9f8\n",
      "Step 4/7 : COPY . ./\n",
      " ---> e261d2bfd98e\n",
      "Step 5/7 : ARG PORT\n",
      " ---> Running in eb02b74edf0c\n",
      "Removing intermediate container eb02b74edf0c\n",
      " ---> e9a418c2d4b7\n",
      "Step 6/7 : ENV PORT=$PORT\n",
      " ---> Running in d7f9a2b161ab\n",
      "Removing intermediate container d7f9a2b161ab\n",
      " ---> a0e4ca78ac87\n",
      "Step 7/7 : CMD exec gunicorn --bind :$PORT main:app  --workers=1 --threads 8 --timeout 1800\n",
      " ---> Running in e4bf14e5299d\n",
      "Removing intermediate container e4bf14e5299d\n",
      " ---> d980bf3a6aeb\n",
      "Successfully built d980bf3a6aeb\n",
      "Successfully tagged us-central1-docker.pkg.dev/rec-ai-demo-326116/ml-serving/index_server:v1\n",
      "PUSH\n",
      "Pushing us-central1-docker.pkg.dev/rec-ai-demo-326116/ml-serving/index_server:v1\n",
      "The push refers to repository [us-central1-docker.pkg.dev/rec-ai-demo-326116/ml-serving/index_server]\n",
      "a9bfbba14511: Preparing\n",
      "6ad17d8e9d8f: Preparing\n",
      "2ed0594d5c30: Preparing\n",
      "d82f4c466b47: Preparing\n",
      "5aa75f4e55e7: Preparing\n",
      "74d6903a940b: Preparing\n",
      "2f9c2b8e82bd: Preparing\n",
      "ba5a5fe43301: Preparing\n",
      "74d6903a940b: Waiting\n",
      "2f9c2b8e82bd: Waiting\n",
      "ba5a5fe43301: Waiting\n",
      "a9bfbba14511: Pushed\n",
      "2ed0594d5c30: Pushed\n",
      "5aa75f4e55e7: Pushed\n",
      "d82f4c466b47: Pushed\n",
      "2f9c2b8e82bd: Pushed\n",
      "74d6903a940b: Pushed\n",
      "ba5a5fe43301: Pushed\n",
      "6ad17d8e9d8f: Pushed\n",
      "v1: digest: sha256:df3097ee6edb03f9f4b4b2fb25b22a307b7ae3410367e6fccbefb37969a48561 size: 1998\n",
      "DONE\n",
      "--------------------------------------------------------------------------------\n",
      "ID                                    CREATE_TIME                DURATION  SOURCE                                                                                            IMAGES                                                                    STATUS\n",
      "bbd1b28e-48a8-4b3b-94e9-318a9827efec  2021-09-20T20:03:49+00:00  2M29S     gs://rec-ai-demo-326116_cloudbuild/source/1632168228.314874-16089a2f9d5547e7927d519977f69a7f.tgz  us-central1-docker.pkg.dev/rec-ai-demo-326116/ml-serving/index_server:v1  SUCCESS\n"
     ]
    }
   ],
   "source": [
    "IMAGE_URL = f'{REGION}-docker.pkg.dev/{PROJECT_ID}/{ARTIFACTS_REPOSITORY_NAME}/{SCANN_MODEL_NAME}:{SCANN_MODEL_VERSION}'\n",
    "PORT=5001\n",
    "\n",
    "SUBSTITUTIONS = ''\n",
    "SUBSTITUTIONS += f'_IMAGE_URL={IMAGE_URL},'\n",
    "SUBSTITUTIONS += f'_PORT={PORT}'\n",
    "\n",
    "!gcloud builds submit --config=index_server/cloudbuild.yaml \\\n",
    "  --substitutions={SUBSTITUTIONS} \\\n",
    "  --timeout=1h"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TPk9Qi93G56d"
   },
   "source": [
    "Run the following command to verify the container image has been built:\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "PvSIUzD9_RS7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Listing items under project rec-ai-demo-326116, location us-central1, repository ml-serving.\n",
      "\n",
      "IMAGE                                                                  DIGEST                                                                   CREATE_TIME          UPDATE_TIME\n",
      "us-central1-docker.pkg.dev/rec-ai-demo-326116/ml-serving/index_server  sha256:df3097ee6edb03f9f4b4b2fb25b22a307b7ae3410367e6fccbefb37969a48561  2021-09-20T20:06:20  2021-09-20T20:06:20\n"
     ]
    }
   ],
   "source": [
    "repository_id = f'{REGION}-docker.pkg.dev/{PROJECT_ID}/{ARTIFACTS_REPOSITORY_NAME}'\n",
    "\n",
    "!gcloud beta artifacts docker images list {repository_id}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UAr0Vsft_RS7"
   },
   "source": [
    "### Create a service account for AI Platform Prediction\r\n",
    "\r\n",
    "Create a service account to run the custom container. This [is required](https://cloud.google.com/ai-platform/prediction/docs/custom-service-account#container-default) in cases where you want to grant specific permissions to the service account."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "cBa56i5g_RS8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created service account [caip-serving].\n"
     ]
    }
   ],
   "source": [
    "SERVICE_ACCOUNT_NAME = 'caip-serving'\n",
    "SERVICE_ACCOUNT_EMAIL = f'{SERVICE_ACCOUNT_NAME}@{PROJECT_ID}.iam.gserviceaccount.com'\n",
    "!gcloud iam service-accounts create {SERVICE_ACCOUNT_NAME} \\\n",
    "  --description=\"Service account for AI Platform Prediction to access cloud resources.\" "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0-5BUPqT_RS8"
   },
   "source": [
    "Grant the `Cloud ML Engine (AI Platform)` service account the `iam.serviceAccountAdmin` privilege, and grant the `caip-serving` service account the privileges required by the ScaNN matching service, which are `storage.objectViewer` and `ml.developer`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "qUoaWCVJ_RS8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "733956866731\n"
     ]
    }
   ],
   "source": [
    "!gcloud projects describe {PROJECT_ID} --format=\"value(projectNumber)\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "LzMJ60X-_RS9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated IAM policy for project [rec-ai-demo-326116].\n",
      "bindings:\n",
      "- members:\n",
      "  - serviceAccount:service-733956866731@gcp-sa-aiplatform-cc.iam.gserviceaccount.com\n",
      "  role: roles/aiplatform.customCodeServiceAgent\n",
      "- members:\n",
      "  - serviceAccount:service-733956866731@gcp-sa-aiplatform.iam.gserviceaccount.com\n",
      "  role: roles/aiplatform.serviceAgent\n",
      "- members:\n",
      "  - serviceAccount:service-733956866731@gcp-sa-artifactregistry.iam.gserviceaccount.com\n",
      "  role: roles/artifactregistry.serviceAgent\n",
      "- members:\n",
      "  - serviceAccount:service-733956866731@gcp-sa-bigquerydatatransfer.iam.gserviceaccount.com\n",
      "  role: roles/bigquerydatatransfer.serviceAgent\n",
      "- members:\n",
      "  - serviceAccount:733956866731@cloudbuild.gserviceaccount.com\n",
      "  - serviceAccount:terraform-sa@rec-ai-demo-326116.iam.gserviceaccount.com\n",
      "  role: roles/cloudbuild.builds.builder\n",
      "- members:\n",
      "  - serviceAccount:service-733956866731@gcp-sa-cloudbuild.iam.gserviceaccount.com\n",
      "  role: roles/cloudbuild.serviceAgent\n",
      "- members:\n",
      "  - serviceAccount:service-733956866731@compute-system.iam.gserviceaccount.com\n",
      "  role: roles/compute.serviceAgent\n",
      "- members:\n",
      "  - serviceAccount:service-733956866731@containerregistry.iam.gserviceaccount.com\n",
      "  role: roles/containerregistry.ServiceAgent\n",
      "- members:\n",
      "  - serviceAccount:service-733956866731@dataflow-service-producer-prod.iam.gserviceaccount.com\n",
      "  role: roles/dataflow.serviceAgent\n",
      "- members:\n",
      "  - serviceAccount:733956866731-compute@developer.gserviceaccount.com\n",
      "  - serviceAccount:733956866731@cloudservices.gserviceaccount.com\n",
      "  - serviceAccount:rec-ai-demo-326116@appspot.gserviceaccount.com\n",
      "  role: roles/editor\n",
      "- members:\n",
      "  - serviceAccount:service-733956866731@gcp-sa-firestore.iam.gserviceaccount.com\n",
      "  role: roles/firestore.serviceAgent\n",
      "- members:\n",
      "  - serviceAccount:service-733956866731@cloud-ml.google.com.iam.gserviceaccount.com\n",
      "  role: roles/iam.serviceAccountAdmin\n",
      "- members:\n",
      "  - serviceAccount:service-733956866731@cloud-ml.google.com.iam.gserviceaccount.com\n",
      "  role: roles/ml.serviceAgent\n",
      "- members:\n",
      "  - serviceAccount:service-733956866731@gcp-sa-notebooks.iam.gserviceaccount.com\n",
      "  role: roles/notebooks.serviceAgent\n",
      "- members:\n",
      "  - serviceAccount:terraform-sa@rec-ai-demo-326116.iam.gserviceaccount.com\n",
      "  - user:jwortz@google.com\n",
      "  role: roles/owner\n",
      "- members:\n",
      "  - serviceAccount:service-733956866731@gcp-sa-pubsub.iam.gserviceaccount.com\n",
      "  role: roles/pubsub.serviceAgent\n",
      "- members:\n",
      "  - serviceAccount:service-733956866731@service-networking.iam.gserviceaccount.com\n",
      "  role: roles/servicenetworking.serviceAgent\n",
      "- members:\n",
      "  - serviceAccount:service-733956866731@gcp-sa-vpcaccess.iam.gserviceaccount.com\n",
      "  role: roles/vpcaccess.serviceAgent\n",
      "etag: BwXMctQn9k0=\n",
      "version: 1\n",
      "Updated IAM policy for project [rec-ai-demo-326116].\n",
      "bindings:\n",
      "- members:\n",
      "  - serviceAccount:service-733956866731@gcp-sa-aiplatform-cc.iam.gserviceaccount.com\n",
      "  role: roles/aiplatform.customCodeServiceAgent\n",
      "- members:\n",
      "  - serviceAccount:service-733956866731@gcp-sa-aiplatform.iam.gserviceaccount.com\n",
      "  role: roles/aiplatform.serviceAgent\n",
      "- members:\n",
      "  - serviceAccount:service-733956866731@gcp-sa-artifactregistry.iam.gserviceaccount.com\n",
      "  role: roles/artifactregistry.serviceAgent\n",
      "- members:\n",
      "  - serviceAccount:service-733956866731@gcp-sa-bigquerydatatransfer.iam.gserviceaccount.com\n",
      "  role: roles/bigquerydatatransfer.serviceAgent\n",
      "- members:\n",
      "  - serviceAccount:733956866731@cloudbuild.gserviceaccount.com\n",
      "  - serviceAccount:terraform-sa@rec-ai-demo-326116.iam.gserviceaccount.com\n",
      "  role: roles/cloudbuild.builds.builder\n",
      "- members:\n",
      "  - serviceAccount:service-733956866731@gcp-sa-cloudbuild.iam.gserviceaccount.com\n",
      "  role: roles/cloudbuild.serviceAgent\n",
      "- members:\n",
      "  - serviceAccount:service-733956866731@compute-system.iam.gserviceaccount.com\n",
      "  role: roles/compute.serviceAgent\n",
      "- members:\n",
      "  - serviceAccount:service-733956866731@containerregistry.iam.gserviceaccount.com\n",
      "  role: roles/containerregistry.ServiceAgent\n",
      "- members:\n",
      "  - serviceAccount:service-733956866731@dataflow-service-producer-prod.iam.gserviceaccount.com\n",
      "  role: roles/dataflow.serviceAgent\n",
      "- members:\n",
      "  - serviceAccount:733956866731-compute@developer.gserviceaccount.com\n",
      "  - serviceAccount:733956866731@cloudservices.gserviceaccount.com\n",
      "  - serviceAccount:rec-ai-demo-326116@appspot.gserviceaccount.com\n",
      "  role: roles/editor\n",
      "- members:\n",
      "  - serviceAccount:service-733956866731@gcp-sa-firestore.iam.gserviceaccount.com\n",
      "  role: roles/firestore.serviceAgent\n",
      "- members:\n",
      "  - serviceAccount:service-733956866731@cloud-ml.google.com.iam.gserviceaccount.com\n",
      "  role: roles/iam.serviceAccountAdmin\n",
      "- members:\n",
      "  - serviceAccount:service-733956866731@cloud-ml.google.com.iam.gserviceaccount.com\n",
      "  role: roles/ml.serviceAgent\n",
      "- members:\n",
      "  - serviceAccount:service-733956866731@gcp-sa-notebooks.iam.gserviceaccount.com\n",
      "  role: roles/notebooks.serviceAgent\n",
      "- members:\n",
      "  - serviceAccount:terraform-sa@rec-ai-demo-326116.iam.gserviceaccount.com\n",
      "  - user:jwortz@google.com\n",
      "  role: roles/owner\n",
      "- members:\n",
      "  - serviceAccount:service-733956866731@gcp-sa-pubsub.iam.gserviceaccount.com\n",
      "  role: roles/pubsub.serviceAgent\n",
      "- members:\n",
      "  - serviceAccount:service-733956866731@service-networking.iam.gserviceaccount.com\n",
      "  role: roles/servicenetworking.serviceAgent\n",
      "- members:\n",
      "  - serviceAccount:caip-serving@rec-ai-demo-326116.iam.gserviceaccount.com\n",
      "  role: roles/storage.objectViewer\n",
      "- members:\n",
      "  - serviceAccount:service-733956866731@gcp-sa-vpcaccess.iam.gserviceaccount.com\n",
      "  role: roles/vpcaccess.serviceAgent\n",
      "etag: BwXMctRCVVc=\n",
      "version: 1\n",
      "Updated IAM policy for project [rec-ai-demo-326116].\n",
      "bindings:\n",
      "- members:\n",
      "  - serviceAccount:service-733956866731@gcp-sa-aiplatform-cc.iam.gserviceaccount.com\n",
      "  role: roles/aiplatform.customCodeServiceAgent\n",
      "- members:\n",
      "  - serviceAccount:service-733956866731@gcp-sa-aiplatform.iam.gserviceaccount.com\n",
      "  role: roles/aiplatform.serviceAgent\n",
      "- members:\n",
      "  - serviceAccount:service-733956866731@gcp-sa-artifactregistry.iam.gserviceaccount.com\n",
      "  role: roles/artifactregistry.serviceAgent\n",
      "- members:\n",
      "  - serviceAccount:service-733956866731@gcp-sa-bigquerydatatransfer.iam.gserviceaccount.com\n",
      "  role: roles/bigquerydatatransfer.serviceAgent\n",
      "- members:\n",
      "  - serviceAccount:733956866731@cloudbuild.gserviceaccount.com\n",
      "  - serviceAccount:terraform-sa@rec-ai-demo-326116.iam.gserviceaccount.com\n",
      "  role: roles/cloudbuild.builds.builder\n",
      "- members:\n",
      "  - serviceAccount:service-733956866731@gcp-sa-cloudbuild.iam.gserviceaccount.com\n",
      "  role: roles/cloudbuild.serviceAgent\n",
      "- members:\n",
      "  - serviceAccount:service-733956866731@compute-system.iam.gserviceaccount.com\n",
      "  role: roles/compute.serviceAgent\n",
      "- members:\n",
      "  - serviceAccount:service-733956866731@containerregistry.iam.gserviceaccount.com\n",
      "  role: roles/containerregistry.ServiceAgent\n",
      "- members:\n",
      "  - serviceAccount:service-733956866731@dataflow-service-producer-prod.iam.gserviceaccount.com\n",
      "  role: roles/dataflow.serviceAgent\n",
      "- members:\n",
      "  - serviceAccount:733956866731-compute@developer.gserviceaccount.com\n",
      "  - serviceAccount:733956866731@cloudservices.gserviceaccount.com\n",
      "  - serviceAccount:rec-ai-demo-326116@appspot.gserviceaccount.com\n",
      "  role: roles/editor\n",
      "- members:\n",
      "  - serviceAccount:service-733956866731@gcp-sa-firestore.iam.gserviceaccount.com\n",
      "  role: roles/firestore.serviceAgent\n",
      "- members:\n",
      "  - serviceAccount:service-733956866731@cloud-ml.google.com.iam.gserviceaccount.com\n",
      "  role: roles/iam.serviceAccountAdmin\n",
      "- members:\n",
      "  - serviceAccount:caip-serving@rec-ai-demo-326116.iam.gserviceaccount.com\n",
      "  role: roles/ml.developer\n",
      "- members:\n",
      "  - serviceAccount:service-733956866731@cloud-ml.google.com.iam.gserviceaccount.com\n",
      "  role: roles/ml.serviceAgent\n",
      "- members:\n",
      "  - serviceAccount:service-733956866731@gcp-sa-notebooks.iam.gserviceaccount.com\n",
      "  role: roles/notebooks.serviceAgent\n",
      "- members:\n",
      "  - serviceAccount:terraform-sa@rec-ai-demo-326116.iam.gserviceaccount.com\n",
      "  - user:jwortz@google.com\n",
      "  role: roles/owner\n",
      "- members:\n",
      "  - serviceAccount:service-733956866731@gcp-sa-pubsub.iam.gserviceaccount.com\n",
      "  role: roles/pubsub.serviceAgent\n",
      "- members:\n",
      "  - serviceAccount:service-733956866731@service-networking.iam.gserviceaccount.com\n",
      "  role: roles/servicenetworking.serviceAgent\n",
      "- members:\n",
      "  - serviceAccount:caip-serving@rec-ai-demo-326116.iam.gserviceaccount.com\n",
      "  role: roles/storage.objectViewer\n",
      "- members:\n",
      "  - serviceAccount:service-733956866731@gcp-sa-vpcaccess.iam.gserviceaccount.com\n",
      "  role: roles/vpcaccess.serviceAgent\n",
      "etag: BwXMctRcApc=\n",
      "version: 1\n"
     ]
    }
   ],
   "source": [
    "!gcloud projects add-iam-policy-binding {PROJECT_ID} \\\n",
    "  --role=roles/iam.serviceAccountAdmin \\\n",
    "  --member=serviceAccount:service-{PROJECT_NUMBER}@cloud-ml.google.com.iam.gserviceaccount.com\n",
    "\n",
    "!gcloud projects add-iam-policy-binding {PROJECT_ID} \\\n",
    "  --role=roles/storage.objectViewer \\\n",
    "  --member=serviceAccount:{SERVICE_ACCOUNT_EMAIL}\n",
    "    \n",
    "!gcloud projects add-iam-policy-binding {PROJECT_ID} \\\n",
    "  --role=roles/ml.developer \\\n",
    "  --member=serviceAccount:{SERVICE_ACCOUNT_EMAIL}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1-x11wBH_RS9"
   },
   "source": [
    "### Deploy the custom container to AI Platform Prediction\r\n",
    "\r\n",
    "Create the ANN index model resource in AI Platform:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "CfeleaCW_RS-"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using endpoint [https://us-central1-ml.googleapis.com/]\n",
      "Created ai platform model [projects/rec-ai-demo-326116/models/index_server].\n"
     ]
    }
   ],
   "source": [
    "!gcloud ai-platform models create {SCANN_MODEL_NAME} --region={REGION}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "I9TcigBmHOin"
   },
   "source": [
    "Deploy the custom container to AI Platform prediction. Note that you use the `env-vars` parameter to pass environmental variables to the Flask application in the container. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "fg9wtS2__RS_"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using endpoint [https://us-central1-ml.googleapis.com/]\n",
      "Creating version (this might take a few minutes)......done.                    \n",
      "The model version is deployed to AI Platform Prediction.\n"
     ]
    }
   ],
   "source": [
    "HEALTH_ROUTE=f'/v1/models/{SCANN_MODEL_NAME}/versions/{SCANN_MODEL_VERSION}'\n",
    "PREDICT_ROUTE=f'/v1/models/{SCANN_MODEL_NAME}/versions/{SCANN_MODEL_VERSION}:predict'\n",
    "\n",
    "ENV_VARIABLES = f'PROJECT_ID={PROJECT_ID},'\n",
    "ENV_VARIABLES += f'REGION={REGION},'\n",
    "ENV_VARIABLES += f'INDEX_DIR={INDEX_DIR},'\n",
    "ENV_VARIABLES += f'EMBEDDNIG_LOOKUP_MODEL_NAME={EMBEDDNIG_LOOKUP_MODEL_NAME},'\n",
    "ENV_VARIABLES += f'EMBEDDNIG_LOOKUP_MODEL_VERSION={EMBEDDNIG_LOOKUP_MODEL_VERSION}'\n",
    "\n",
    "!gcloud beta ai-platform versions create {SCANN_MODEL_VERSION} \\\n",
    "  --region={REGION} \\\n",
    "  --model={SCANN_MODEL_NAME} \\\n",
    "  --image={IMAGE_URL} \\\n",
    "  --ports={PORT} \\\n",
    "  --predict-route={PREDICT_ROUTE} \\\n",
    "  --health-route={HEALTH_ROUTE} \\\n",
    "  --machine-type=n1-standard-4 \\\n",
    "  --env-vars={ENV_VARIABLES} \\\n",
    "  --service-account={SERVICE_ACCOUNT_EMAIL}\n",
    "\n",
    "print(\"The model version is deployed to AI Platform Prediction.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WzCcA58l_RS_"
   },
   "source": [
    "### Test the Deployed ScaNN Index Service\r\n",
    "\r\n",
    "After deploying the custom container, test it by running the `caip_scann_match` method. This method accepts the parameter `query_items`, whose value is converted into a space-separated string of item IDs and treated as a single query. That is, a single embedding vector is retrieved from the embedding lookup model, and similar item IDs are retrieved from the ScaNN index given this embedding vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "w5OlMGuD_RS_"
   },
   "outputs": [],
   "source": [
    "from google.cloud import datastore\n",
    "import requests\n",
    "client = datastore.Client(PROJECT_ID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "WwzuijuH_RTA"
   },
   "outputs": [],
   "source": [
    "def caip_scann_match(query_items, show=10):\n",
    "  request_body = {\n",
    "      'instances': [{\n",
    "          'query':' '.join(query_items), \n",
    "          'show':show\n",
    "      }]\n",
    "   }\n",
    "  \n",
    "  service_name = f'projects/{PROJECT_ID}/models/{SCANN_MODEL_NAME}/versions/{SCANN_MODEL_VERSION}'\n",
    "  print(f'Calling: {service_name}')  \n",
    "  response = service.projects().predict(\n",
    "    name=service_name, body=request_body).execute()\n",
    "\n",
    "  if 'error' in response:\n",
    "    raise RuntimeError(response['error'])\n",
    "\n",
    "  match_tokens = response['predictions']\n",
    "  keys = [client.key(KIND, int(key)) for key in match_tokens]\n",
    "  items = client.get_multi(keys)\n",
    "  return items\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ctXsOxhDHsX_"
   },
   "source": [
    "Call the `caip_scann_match` method with five item IDs and request five match items for each:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "620GvSzr_RTA"
   },
   "outputs": [],
   "source": [
    "products = {\n",
    "    '4096': \"AX Paris Strapless Spot Print Orange Romper\",\n",
    "    '5120': \"Lee Women's Plus-Size Comfort Fit Straight Leg Pant\",\n",
    "    '7424': \"Allegra K Woman Plaid Elastic Waist Preppy Above Knee Skirt Gray Black S\",\n",
    "    '4352': \"Silver Jeans Juniors Suki Surplus Mid Rise Bootcut Jean\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "YiYAYVG9_RTB"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AX Paris Strapless Spot Print Orange Romper\n",
      "==================\n",
      "Calling: projects/rec-ai-demo-326116/models/index_server/versions/v1\n",
      "- Active: Woman Within Plus Size Top sweatshirt in cozy light sherpa fleece\n",
      "- Jumpsuits & Rompers: AX Paris Strapless Spot Print Orange Romper\n",
      "- Blazers & Jackets: Georgie Women's Redford Blazer\n",
      "- Suits: LE SUIT Gold Color Collar Jacket/Skirt Suit\n",
      "- Tops & Tees: Van Heusen Men's Fitted Long Sleeve Wrinkle Free Satin Stripe Shirt\n",
      "\n",
      "Lee Women's Plus-Size Comfort Fit Straight Leg Pant\n",
      "==================\n",
      "Calling: projects/rec-ai-demo-326116/models/index_server/versions/v1\n",
      "- Dresses: Allegra K Women Dots Print Elastic Waist Mini Dress Black Beige L w Brown Belt\n",
      "- Pants & Capris: Lee Women's Plus-Size Comfort Fit Straight Leg Pant\n",
      "- Skirts: MimiSkirts Stretch Mini Skirt\n",
      "- Socks & Hosiery: Thorlo Unisex Experia Running Sock\n",
      "- Plus: HUE Women's Opaque Sheer to Waist Opaque Tight\n",
      "\n",
      "Allegra K Woman Plaid Elastic Waist Preppy Above Knee Skirt Gray Black S\n",
      "==================\n",
      "Calling: projects/rec-ai-demo-326116/models/index_server/versions/v1\n",
      "- Tops & Tees: Plus Size Sexy RED Black Lace Corset Top\n",
      "- Dresses: Allegra K Woman Dolman Sleeve Side Shirr Blouse + Tank Dress Black L\n",
      "- Shorts: Roxy Juniors Pull On Short\n",
      "- Skirts: Allegra K Woman Plaid Elastic Waist Preppy Above Knee Skirt Gray Black S\n",
      "- Accessories: Scala Women's Cotton Big Brim Ultraviolet Protection Hat with Inner Drawstring\n",
      "\n",
      "Silver Jeans Juniors Suki Surplus Mid Rise Bootcut Jean\n",
      "==================\n",
      "Calling: projects/rec-ai-demo-326116/models/index_server/versions/v1\n",
      "- Active: Champion Women's Absolute Workout Tight\n",
      "- Dresses: KAMALIKULTURE Women's Long Sleeve Side Draped Dress\n",
      "- Dresses: Allegra K Woman Drawstring Waist Short Sleeve Full-length Dress Heather Gray L\n",
      "- Jeans: Silver Jeans Juniors Suki Surplus Mid Rise Bootcut Jean\n",
      "- Maternity: BellaBand Women's Everyday Bellaband\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for item_Id, desc in products.items():\n",
    "  print(desc)\n",
    "  print(\"==================\")\n",
    "  similar_items = caip_scann_match([item_Id], 5)\n",
    "  for similar_item in similar_items:\n",
    "    print(f'- {similar_item[\"sub_category\"]}: {similar_item[\"name\"]}')\n",
    "  print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lt7-YDSe_RTB"
   },
   "source": [
    "## (Optional) Deploy the matrix factorization model to AI Platform Prediction\r\n",
    "\r\n",
    "Optionally, you can deploy the matrix factorization model in order to perform exact item matching. The model takes `Item1_Id` as an input and outputs the top 50 recommended `item2_Ids`.\r\n",
    "\r\n",
    "Exact matching returns better results, but takes significantly longer than approximate nearest neighbor matching. You might want to use exact item matching in cases where you are working with a very small data set and where latency isn't a primary concern."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YSDzSk4T_RTC"
   },
   "source": [
    "### Export the model from BigQuery ML to Cloud Storage as a SavedModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "You are running on a Google Compute Engine virtual machine.\n",
      "It is recommended that you use service accounts for authentication.\n",
      "\n",
      "You can run:\n",
      "\n",
      "  $ gcloud config set account `ACCOUNT`\n",
      "\n",
      "to switch accounts if necessary.\n",
      "\n",
      "Your credentials may be visible to others with access to this\n",
      "virtual machine. Are you sure you want to authenticate with\n",
      "your personal account?\n",
      "\n",
      "Do you want to continue (Y/n)?  \n",
      "\u001b[1;33mWARNING:\u001b[0m Re-using locally stored credentials for [jwortz@google.com]. To fetch new credentials, re-run the command with the `--force` flag.\n",
      "\n",
      "You are now logged in as [jwortz@google.com].\n",
      "Your current project is [rec-ai-demo-326116].  You can change this setting by running:\n",
      "  $ gcloud config set project PROJECT_ID\n"
     ]
    }
   ],
   "source": [
    "# need a quick user login\n",
    "\n",
    "!echo Y | gcloud auth login jwortz@google.com --activate --launch-browser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "id": "YVmmFvLk_RTC"
   },
   "outputs": [],
   "source": [
    "BQ_DATASET_NAME = 'css_retail'\n",
    "BQML_MODEL_NAME = 'item_matching_model'\n",
    "BQML_MODEL_VERSION = 'v1' \n",
    "BQML_MODEL_OUTPUT_DIR = f'gs://{BUCKET}/bqml/item_matching_model'\n",
    "\n",
    "!bq --quiet extract -m {BQ_DATASET_NAME}.{BQML_MODEL_NAME} {BQML_MODEL_OUTPUT_DIR}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "id": "Q4xzyUte_RTC"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The given SavedModel SignatureDef contains the following input(s):\n",
      "  inputs['item1_Id'] tensor_info:\n",
      "      dtype: DT_INT64\n",
      "      shape: (-1)\n",
      "      name: item1_Id:0\n",
      "The given SavedModel SignatureDef contains the following output(s):\n",
      "  outputs['predicted_item2_Id'] tensor_info:\n",
      "      dtype: DT_STRING\n",
      "      shape: (-1, 50)\n",
      "      name: item_list:0\n",
      "  outputs['predicted_score_confidence'] tensor_info:\n",
      "      dtype: DT_DOUBLE\n",
      "      shape: (-1, 50)\n",
      "      name: item_ratings:0\n",
      "Method name is: tensorflow/serving/predict\n"
     ]
    }
   ],
   "source": [
    "!saved_model_cli show --dir {BQML_MODEL_OUTPUT_DIR} --tag_set serve --signature_def serving_default"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kWbEnUnO_RTC"
   },
   "source": [
    "### Deploy the exact matching model to AI Platform Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "id": "Es8Tp9HM_RTD"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using endpoint [https://us-central1-ml.googleapis.com/]\n",
      "Created ai platform model [projects/rec-ai-demo-326116/models/item_matching_model].\n"
     ]
    }
   ],
   "source": [
    "!gcloud ai-platform models create {BQML_MODEL_NAME} --region={REGION}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "id": "nNOVgOD9_RTD"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using endpoint [https://us-central1-ml.googleapis.com/]\n",
      "Creating version (this might take a few minutes)......done.                    \n",
      "The model version is deployed to AI Platform Predicton.\n"
     ]
    }
   ],
   "source": [
    "!gcloud ai-platform versions create {BQML_MODEL_VERSION} \\\n",
    "  --region={REGION} \\\n",
    "  --model={BQML_MODEL_NAME} \\\n",
    "  --origin={BQML_MODEL_OUTPUT_DIR} \\\n",
    "  --runtime-version=2.2 \\\n",
    "  --framework=TensorFlow \\\n",
    "  --python-version=3.7 \\\n",
    "  --machine-type=n1-standard-2\n",
    "\n",
    "print(\"The model version is deployed to AI Platform Predicton.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "id": "n9MDaT3P_RTD"
   },
   "outputs": [],
   "source": [
    "def caip_bqml_matching(input_items, show):\n",
    "  request_body = {'instances': input_items}\n",
    "  service_name = f'projects/{PROJECT_ID}/models/{BQML_MODEL_NAME}/versions/{BQML_MODEL_VERSION}'\n",
    "  print(f'Calling : {service_name}')\n",
    "  response = service.projects().predict(\n",
    "    name=service_name, body=request_body).execute()\n",
    "\n",
    "  if 'error' in response:\n",
    "    raise RuntimeError(response['error'])\n",
    "    \n",
    "  \n",
    "  match_tokens = response['predictions'][0][\"predicted_item2_Id\"][:show]\n",
    "  keys = [client.key(KIND, int(key)) for key in match_tokens]\n",
    "  items = client.get_multi(keys)\n",
    "  return items\n",
    "\n",
    "  return response['predictions']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "id": "bHvFNZ78_RTD"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AX Paris Strapless Spot Print Orange Romper\n",
      "==================\n",
      "Calling : projects/rec-ai-demo-326116/models/item_matching_model/versions/v1\n",
      "- Outerwear & Coats: Columbia Women's Benton Springs Full Zip Jacket\n",
      "- Accessories: Ray-Ban RB2132  New Wayfarer Sunglasses\n",
      "- Jeans: Levi's Men's 505 Straight (Regular) Fit Jean\n",
      "- Jeans: Levi's Men's 501 Jean\n",
      "- Outerwear & Coats: Columbia Men's Steens Mountain Full Zip\n",
      "\n",
      "Lee Women's Plus-Size Comfort Fit Straight Leg Pant\n",
      "==================\n",
      "Calling : projects/rec-ai-demo-326116/models/item_matching_model/versions/v1\n",
      "- Outerwear & Coats: Columbia Women's Benton Springs Full Zip Jacket\n",
      "- Accessories: Ray-Ban RB2132  New Wayfarer Sunglasses\n",
      "- Jeans: Levi's Men's 501 Jean\n",
      "- Outerwear & Coats: Columbia Men's Steens Mountain Full Zip\n",
      "- Accessories: Ray-Ban RB2132  New Wayfarer Sunglasses\n",
      "\n",
      "Allegra K Woman Plaid Elastic Waist Preppy Above Knee Skirt Gray Black S\n",
      "==================\n",
      "Calling : projects/rec-ai-demo-326116/models/item_matching_model/versions/v1\n",
      "- Accessories: Ray-Ban RB2132  New Wayfarer Sunglasses\n",
      "- Jeans: Levi's Men's 505 Straight (Regular) Fit Jean\n",
      "- Jeans: Levi's Men's 501 Jean\n",
      "- Outerwear & Coats: Columbia Men's Steens Mountain Full Zip\n",
      "- Accessories: Ray-Ban RB2132  New Wayfarer Sunglasses\n",
      "\n",
      "Silver Jeans Juniors Suki Surplus Mid Rise Bootcut Jean\n",
      "==================\n",
      "Calling : projects/rec-ai-demo-326116/models/item_matching_model/versions/v1\n",
      "- Accessories: Scarfand's Leopard Infinity Scarf\n",
      "- Accessories: Ray-Ban RB2132  New Wayfarer Sunglasses\n",
      "- Jeans: Levi's Men's 505 Straight (Regular) Fit Jean\n",
      "- Jeans: Levi's Men's 501 Jean\n",
      "- Accessories: Ray-Ban RB2132  New Wayfarer Sunglasses\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for item_Id, desc in products.items():\n",
    "  print(desc)\n",
    "  print(\"==================\")\n",
    "  similar_items = caip_bqml_matching([int(item_Id)], 5)\n",
    "  for similar_item in similar_items:\n",
    "    print(f'- {similar_item[\"sub_category\"]}: {similar_item[\"name\"]}')\n",
    "  print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6uUOZgLQ_RTE"
   },
   "source": [
    "## License\n",
    "\n",
    "Copyright 2020 Google LLC\n",
    "\n",
    "Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "you may not use this file except in compliance with the License. You may obtain a copy of the License at: http://www.apache.org/licenses/LICENSE-2.0\n",
    "\n",
    "Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. \n",
    "\n",
    "See the License for the specific language governing permissions and limitations under the License.\n",
    "\n",
    "**This is not an official Google product but sample code provided for an educational purpose**"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "05_deploy_lookup_and_scann_caip.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "environment": {
   "name": "tf2-gpu.2-6.m79",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-6:m79"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
