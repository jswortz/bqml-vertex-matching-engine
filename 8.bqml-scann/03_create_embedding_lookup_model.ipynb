{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2WVKxCwTsFVK"
   },
   "source": [
    "# Part 3: Create a model to serve the item embedding data\n",
    "\n",
    "This notebook is the third of five notebooks that guide you through running the [Real-time Item-to-item Recommendation with BigQuery ML Matrix Factorization and ScaNN](https://github.com/GoogleCloudPlatform/analytics-componentized-patterns/tree/master/retail/recommendation-system/bqml-scann) solution.\n",
    "\n",
    "Use this notebook to wrap the item embeddings data in a Keras model that can act as an item-embedding lookup, then export the model as a SavedModel.\n",
    "\n",
    "Before starting this notebook, you must run the [02_export_bqml_mf_embeddings](02_export_bqml_mf_embeddings.ipynb) notebook to process the item embeddings data and export it to Cloud Storage.\n",
    "\n",
    "After completing this notebook, run the [04_build_embeddings_scann](04_build_embeddings_scann.ipynb) notebook to create an approximate nearest neighbor index for the item embeddings.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vLLtPpTQSQM-"
   },
   "source": [
    "## Setup\r\n",
    "\r\n",
    "Import the required libraries, configure the environment variables, and authenticate your GCP account."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lq0qelfbSSnR"
   },
   "source": [
    "### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "bup8vvpRSWg2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensorflow version: 2.6.0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "print(f'Tensorflow version: {tf.__version__}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ty3pxeh3Sej9"
   },
   "source": [
    "### Configure GCP environment settings\r\n",
    "\r\n",
    "Update the following variables to reflect the values for your GCP environment:\r\n",
    "\r\n",
    "+ `PROJECT_ID`: The ID of the Google Cloud project you are using to implement this solution.\r\n",
    "+ `BUCKET`: The name of the Cloud Storage bucket you created to use with this solution. The `BUCKET` value should be just the bucket name, so `myBucket` rather than `gs://myBucket`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "Yx83a_PasCBa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated property [core/project].\n"
     ]
    }
   ],
   "source": [
    "PROJECT_ID = 'rec-ai-demo-326116' # Change to your project.\n",
    "BUCKET = 'rec_bq_jsw' # Change to the bucket you created.\n",
    "EMBEDDING_FILES_PATH = f'gs://{BUCKET}/bqml/item_embeddings/embeddings-*'\n",
    "MODEL_OUTPUT_DIR = f'gs://{BUCKET}/bqml/embedding_lookup_model'\n",
    "\n",
    "!gcloud config set project $PROJECT_ID"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "My7F5vUCShdv"
   },
   "source": [
    "### Authenticate your GCP account\n",
    "This is required if you run the notebook in Colab. If you use an AI Platform notebook, you should already be authenticated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "PZAUnfyFShls"
   },
   "outputs": [],
   "source": [
    "try:\n",
    "  from google.colab import auth\n",
    "  auth.authenticate_user()\n",
    "  print(\"Colab user is authenticated.\")\n",
    "except: pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hCgB7fjuV9fP"
   },
   "source": [
    "## Create the embedding lookup model\r\n",
    "\r\n",
    "You use the `EmbeddingLookup` class to create the item embedding lookup model. The `EmbeddingLookup` class inherits from [tf.keras.Model](https://www.tensorflow.org/api_docs/python/tf/keras/Model), and is implemented in the\r\n",
    "[lookup_creator.py](embeddings_lookup/lookup_creator.py)\r\n",
    "module.\r\n",
    "\r\n",
    "The `EmbeddingLookup `class works as follows:\r\n",
    "\r\n",
    "1. Accepts the `embedding_files_prefix` variable in the class constructor. This variable points to the Cloud Storage location of the CSV files containing the item embedding data.     \r\n",
    "1. Reads and parses the item embedding CSV files.\r\n",
    "1. Populates the `vocabulary` and `embeddings` class variables. `vocabulary` is an array of item IDs, while `embeddings` is a Numpy array with the shape (*number of embeddings*, *embedding dimensions*). \r\n",
    "1. Appends the `oov_embedding` variable to the `embeddings` variable. The `oov_embedding` variable value is all zeros, and it represents the out of vocabulary (OOV) embedding vector. The `oov_embedding` variable is used when an invalid (\"out of vocabulary\", or OOV) item ID is submitted, in which case an embedding vector of zeros is returned.\r\n",
    "1. Writes the `vocabulary` value to a file, one array element per line, so it can be used as a model asset by the SavedModel.\r\n",
    "1. Uses `token_to_idx`, a `tf.lookup.StaticHashTable` object, to map the\r\n",
    "   item ID to the index of the embedding vector in the `embeddings` Numpy array.\r\n",
    "1. Accepts a list of strings with the `__call__` method of the model. Each string represents the item ID(s) for which the embeddings are to be retrieved. If the input list contains _N_ strings, then _N_ embedding vectors are returned. \r\n",
    "\r\n",
    "    Note that each string in the input list may contain one or more space-separated item IDs. If multiple item IDs are present, the embedding   vectors of these item IDs are retrieved and _combined_ (by averaging)   into a single embedding vector. This makes it possible to fetch an embedding vector representing a set of items (like a playlist) rather than just a single item."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "x-zb5lLRKUbr"
   },
   "source": [
    "### Clear the model export directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "koSO5kd7V9fP"
   },
   "outputs": [],
   "source": [
    "if tf.io.gfile.exists(MODEL_OUTPUT_DIR):\n",
    "  print(\"Removing {} contents...\".format(MODEL_OUTPUT_DIR))\n",
    "  tf.io.gfile.rmtree(MODEL_OUTPUT_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vYnm0eqkK2kx"
   },
   "source": [
    "### Create the model and export the SavedModel file\r\n",
    "\r\n",
    "Call the `export_saved_model` method, which uses the `EmbeddingLookup` class to create the model and then exports the resulting SavedModel file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "IW1amfSCYMn5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Instantiating embedding lookup model...\n",
      "Loading embeddings from files...\n",
      "Loading embeddings in gs://rec_bq_jsw/bqml/item_embeddings/embeddings-00000-of-00001.csv ...\n",
      "Embeddings loaded.\n",
      "Embeddings: (2934, 50)\n",
      "Writing vocabulary to file...\n",
      "Vocabulary file written and will be added as a model asset.\n",
      "Model is Instantiated.\n",
      "Exporting embedding lookup model as a SavedModel...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-09-20 16:55:30.883878: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/lib64:/usr/local/nccl2/lib:/usr/local/cuda/extras/CUPTI/lib64\n",
      "2021-09-20 16:55:30.883919: E tensorflow/stream_executor/cuda/cuda_driver.cc:313] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2021-09-20 16:55:30.883945: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (tf-26): /proc/driver/nvidia/version does not exist\n",
      "2021-09-20 16:55:30.884280: I tensorflow/core/platform/cpu_feature_guard.cc:143] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\n",
      "2021-09-20 16:55:30.893131: I tensorflow/core/platform/profile_utils/cpu_utils.cc:102] CPU Frequency: 2299995000 Hz\n",
      "2021-09-20 16:55:30.893474: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fe024000b20 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-09-20 16:55:30.893500: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <embeddings_lookup.lookup_creator.EmbeddingLookup object at 0x7fe0b4138fd0>, because it is not built.\n",
      "WARNING:tensorflow:From /home/jupyter/.local/lib/python3.7/site-packages/tensorflow/python/ops/resource_variable_ops.py:1666: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-09-20 16:55:31.123010: W tensorflow/python/util/util.cc:329] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: gs://rec_bq_jsw/bqml/embedding_lookup_model/assets\n",
      "SavedModel is exported.\n"
     ]
    }
   ],
   "source": [
    "from embeddings_lookup import lookup_creator\n",
    "lookup_creator.export_saved_model(EMBEDDING_FILES_PATH, MODEL_OUTPUT_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0MjA6nlUgAM3"
   },
   "source": [
    "Inspect the exported SavedModel using the `saved_model_cli` command line tool:\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "3Y1o5lVCZqbY"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The given SavedModel SignatureDef contains the following input(s):\n",
      "  inputs['inputs'] tensor_info:\n",
      "      dtype: DT_STRING\n",
      "      shape: (-1)\n",
      "      name: serving_default_inputs:0\n",
      "The given SavedModel SignatureDef contains the following output(s):\n",
      "  outputs['output_0'] tensor_info:\n",
      "      dtype: DT_DOUBLE\n",
      "      shape: (-1, 50)\n",
      "      name: StatefulPartitionedCall_1:0\n",
      "Method name is: tensorflow/serving/predict\n"
     ]
    }
   ],
   "source": [
    "!saved_model_cli show --dir {MODEL_OUTPUT_DIR} --tag_set serve --signature_def serving_default"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "q2waV_yOOluG"
   },
   "source": [
    "### Test the SavedModel file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yX9jAKkkgbyE"
   },
   "source": [
    "Test the SavedModel by loading it and then calling it with input item IDs:\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "serXfA5jfy0h"
   },
   "outputs": [],
   "source": [
    "loaded_model = tf.saved_model.load(MODEL_OUTPUT_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "oVveXWDIqE1V"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embeddings retrieved: (4, 50)\n",
      "4096: [ -1.72466953 -20.72278509   2.38318955   5.38845804  -7.54570316]\n",
      "5120: [-16.08123754 -17.31135493 -13.65108442  15.45910536 -22.22035805]\n",
      "7424: [ -0.98596529 -33.01298703  -7.65918502  14.4493462    2.8797876 ]\n",
      "4352: [ -5.77232774 -20.38927648  20.09983118   7.61426951   0.76448149]\n"
     ]
    }
   ],
   "source": [
    "input_items = ['4096', '5120', '7424', '4352']\n",
    "output = loaded_model(input_items)\n",
    "print(f'Embeddings retrieved: {output.shape}')\n",
    "for idx, embedding in enumerate(output):\n",
    "  print(f'{input_items[idx]}: {embedding[:5]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4Azup3yqgjnJ"
   },
   "source": [
    "The output shows the output embedding vector (the first five elements of each vector) for each input item. Note the following:\r\n",
    "\r\n",
    "+ The second entry in the input list contains two item IDs, `2114402` and `2120788`. The returned vector is the average of the embeddings of these two items.\r\n",
    "+ The third entry in the input list, `abc123`, is an invalid item ID, so the returned embedding vector contains zeros.\r\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2zkAH5zH5n4g"
   },
   "source": [
    "## License\n",
    "\n",
    "Copyright 2020 Google LLC\n",
    "\n",
    "Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "you may not use this file except in compliance with the License. You may obtain a copy of the License at: http://www.apache.org/licenses/LICENSE-2.0\n",
    "\n",
    "Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. \n",
    "\n",
    "See the License for the specific language governing permissions and limitations under the License.\n",
    "\n",
    "**This is not an official Google product but sample code provided for an educational purpose**"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "03_create_embedding_lookup_model.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "environment": {
   "name": "tf2-gpu.2-6.m79",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-6:m79"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
